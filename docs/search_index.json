[["index.html", "A Minimal Book Example Preface", " A Minimal Book Example Sara Haman, Adam Lashley, Reilly Stanton, Benjamin Weisman 2020-10-17 Preface This project was completed to satisfy the requirements of a project assigned to students in the Fall 2020 Data Munging and Exploratory Data Analysis at New College of Florida. This document is broken down into sections pertaining to the discrete steps in the process of exploratory data analysis. In section 1 we give an overview of this project, followed by an explanation of our process for selecting variables. Next, in section 2 we demonstrate our initial failed attempts at pulling the data directly from the API, and explain why we chose to pivot to using the {rscorecard} package for querying our data from the API. Once the data is imported, we assess the quality of the data in section 3 and rename some of the variables to make the data set, and our later analysis, easier to interpret. Following this, section 4 contains the statistical analysis of the data, wherein we investigate the relationship between R1 and R2 Carnegie classification status and unemployment rates. This model is the modified by adding the proportion of white students as a moderator, which reveals interesting results. Lastly, in section 6, we present visualizations made using the data from the College Scorecard API and elaborate on the statistical analyses performed in the previous section. "],["intro.html", "Section 1 Introduction", " Section 1 Introduction You can label chapter and section titles using {#label} after them, e.g., we can reference Chapter 1. If you do not manually label them, there will be automatic labels anyway, e.g., Chapter ??. Figures and tables with captions will be placed in figure and table environments, respectively. par(mar = c(4, 4, .1, .1)) plot(pressure, type = &#39;b&#39;, pch = 19) Figure 1.1: Here is a nice figure! Reference a figure by its code chunk label with the fig: prefix, e.g., see Figure 1.1. Similarly, you can reference tables generated from knitr::kable(), e.g., see Table 1.1. knitr::kable( head(iris, 20), caption = &#39;Here is a nice table!&#39;, booktabs = TRUE ) Table 1.1: Here is a nice table! Sepal.Length Sepal.Width Petal.Length Petal.Width Species 5.1 3.5 1.4 0.2 setosa 4.9 3.0 1.4 0.2 setosa 4.7 3.2 1.3 0.2 setosa 4.6 3.1 1.5 0.2 setosa 5.0 3.6 1.4 0.2 setosa 5.4 3.9 1.7 0.4 setosa 4.6 3.4 1.4 0.3 setosa 5.0 3.4 1.5 0.2 setosa 4.4 2.9 1.4 0.2 setosa 4.9 3.1 1.5 0.1 setosa 5.4 3.7 1.5 0.2 setosa 4.8 3.4 1.6 0.2 setosa 4.8 3.0 1.4 0.1 setosa 4.3 3.0 1.1 0.1 setosa 5.8 4.0 1.2 0.2 setosa 5.7 4.4 1.5 0.4 setosa 5.4 3.9 1.3 0.4 setosa 5.1 3.5 1.4 0.3 setosa 5.7 3.8 1.7 0.3 setosa 5.1 3.8 1.5 0.3 setosa You can write citations, too. For example, we are using the bookdown package (Xie 2020) in this sample book, which was built on top of R Markdown and knitr (Xie 2015). "],["import.html", "Section 2 Data Acquisition 2.1 Set-up and API Exploration 2.2 The rscorecard and tidyverse approach", " Section 2 Data Acquisition library(plyr) library(tidyverse) library(Hmisc) library(httr) library(jsonlite) #install.packages(&quot;tmap&quot;) library(tmap) library(leaflet) library(treemap) library(kableExtra) `%notin%` &lt;- Negate(`%in%`) MakePretty &lt;- function(x) { x %&gt;% kbl(align = &quot;c&quot;) %&gt;% kable_material() } 2.1 Set-up and API Exploration For our project, we wanted to practice using API to pass the data into our global environment and attempt to explore and extract our desired variables using base R. As you will see, our attempt failed, but was useful in helping us understand the relational structure of the College Scorecard Data and the limits of simple indexing when dealing with complicated data structures. 2.1.1 Project Directory Management Prior to extracting any of the data, we want to ensure that our project is reproducible. Thus, we first create a sub-directory within the users working directory, which will hold the .csv files we will write containing our variables of interest. proj.dir &lt;- getwd() #dir.create(&quot;Proj1Data&quot;) data.dir &lt;- paste0(proj.dir, &quot;/Proj1Data&quot;) Next, we pass the API key into an object so that it can be called in the GET() function, which pulls the data from the API into out global environment. APIKey = &quot;FELgrGb47PaevTWxqZTt6etFaQVnDbKpcJLaPL6a&quot; res = GET(paste0(&quot;https://api.data.gov/ed/collegescorecard/v1/schools?api_key=&quot;, APIKey)) This data is initially in a raw format that is pulled from a JSON file stored on the API servers. To do this, we first convert the raw data to char and call the fromJSON() function to convert the data to a more R friendly data structure. data = fromJSON(rawToChar(res$content)) is(data) ## [1] &quot;list&quot; &quot;vector&quot; Now that this raw JSON file is converted to a list, we can begin our exploration of the data. 2.1.2 API Exploration We originally intended on using list2env(yearsLi, envir = .GlobalEnv) to split the list into multiple data.frame objects, but the fact that the names of the listed data frames are numeric values will be a problem. When calling these data frames, R will have to decide whether the user input 2012 is calling the data$2012 data set, or the number 2012. This is likely to cause problems in our later analysis, so we have to look at the names() of objects in our data list to see how we might adjust our approach to exploring the data. names(data$results) ## [1] &quot;2012&quot; &quot;2011&quot; &quot;2010&quot; &quot;2009&quot; &quot;1998&quot; &quot;2008&quot; ## [7] &quot;1997&quot; &quot;2007&quot; &quot;1996&quot; &quot;2006&quot; &quot;2005&quot; &quot;school&quot; ## [13] &quot;2004&quot; &quot;2003&quot; &quot;2002&quot; &quot;id&quot; &quot;latest&quot; &quot;1999&quot; ## [19] &quot;2001&quot; &quot;2000&quot; &quot;2018&quot; &quot;ope6_id&quot; &quot;2017&quot; &quot;2016&quot; ## [25] &quot;2015&quot; &quot;2014&quot; &quot;2013&quot; &quot;ope8_id&quot; &quot;location&quot; Upon looking at the names() we noticed that not all of the listed data frames are named after years, and thus are likely contain different data than the others. Therefore, we first extract the non-year data frames, prior to extracting the year data frames with a character alteration (to make them non-numeric), id_data &lt;- data$results[c(&quot;school&quot;, &quot;id&quot;, &quot;location&quot;, &quot;ope6_id&quot;, &quot;ope8_id&quot;)] yearsLi&lt;- data$results[names(data$results) %notin% c(&quot;school&quot;, &quot;id&quot;, &quot;location&quot;, &quot;ope6_id&quot;, &quot;ope8_id&quot;)] names(yearsLi) &lt;- paste0(&quot;yr&quot;, names(yearsLi)) #list2env(yearsLi, envir = .GlobalEnv) At this point, we then called list2env(data$results, envir = .GlobalEnv) to create individual dataframes of each object in the yearsLi list, which helped us understand what was happening at different levels of the data structure, but ultimately left us more confused about how we should approach querying this data. This code, as well as the code we used to analyze these objects below, is commented it out because it creates an unnecessary number of objects in the global environment, but retained in this document to show the attempts we made at exploring the data structure. # #names(yr2012) #contents(id_data$school) #contents(yr2012$academics$program$bachelors) #yr2012$academics$program$bachelors #length(id_data$ope8_id) At this point, the challenge of collecting data directly from the API seemed insurmountable, but we sought a solution and turned to the sage of all data science obstacles: Google. 2.2 The rscorecard and tidyverse approach As expected, we found out savior in the annals of algorithmic wisdom when we stumbled upon a package called {rscorecard}. The {rscorecard} package is a wrapper for the College Scorecard API that takes full advantage of the complexity in this relational data structure by employing useful tools from the tidyverse eco-system. Using {dplyr} functions, specified to this data set, and pipe operators %&gt;% from {magrittr}, the {rscorecard} package provides an astonishingly simple solution for querying data directly from the API. #install.packages(&quot;rscorecard&quot;) library(rscorecard) The package works by accessing the API directly using the users API key as an argument in the sc_key() function. sc_key(APIKey) ## DATAGOV_API_KEY environment variable now set. You may now use sc_get() without specifying a key. As the message above states, once the API key is accessed, the user can append querying functions like sc_filter(), to collect observations that satisfy booleans, sc_select(), to subset the data by columns, and sc_year(), to select the data from a specified year. These functions are mentioned and explained here because they what we use to extract data on Finances, Demographics, and Death Rates from schools that classify as R1 and R2 research institutions. 2.2.1 Finances F_latest &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(&quot;latest&quot;) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! F_2018 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(2018) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! F_2017 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(2017) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! F_2016 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(2016) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! F_2015 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(2015) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! F_latest %&gt;% mutate(year = &quot;latest&quot;) ## # A tibble: 266 x 11 ## control instnm ccbasic stabbr npt4_pub npt4_priv costt4_a grad_debt_mdn ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 India~ 16 IN 10987 NA 20704 22343 ## 2 1 Unive~ 15 KS 18571 NA 24996 21105 ## 3 2 Bosto~ 15 MA NA 33562 70588 16939 ## 4 1 Oakla~ 16 MI 11560 NA 21231 25000 ## 5 1 Unive~ 15 MS 13857 NA 24822 19500 ## 6 1 Misso~ 16 MO 14205 NA 22012 24750 ## 7 2 Washi~ 15 MO NA 27427 71975 16075 ## 8 1 Monta~ 15 MT 18036 NA 20464 23500 ## 9 1 Unive~ 16 NE 13511 NA 18849 20250 ## 10 1 Unive~ 15 NV 10551 NA 17582 18750 ## # ... with 256 more rows, and 3 more variables: avgfacsal &lt;int&gt;, ## # unemp_rate &lt;dbl&gt;, year &lt;chr&gt; F_2018 %&gt;% mutate(year = 2018) ## # A tibble: 266 x 11 ## control instnm ccbasic stabbr npt4_pub npt4_priv costt4_a grad_debt_mdn ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;lgl&gt; ## 1 1 India~ 16 IN 10987 NA 20704 NA ## 2 1 Unive~ 15 KS 18571 NA 24996 NA ## 3 2 Bosto~ 15 MA NA 33562 70588 NA ## 4 1 Oakla~ 16 MI 11560 NA 21231 NA ## 5 1 Unive~ 15 MS 13857 NA 24822 NA ## 6 1 Misso~ 16 MO 14205 NA 22012 NA ## 7 2 Washi~ 15 MO NA 27427 71975 NA ## 8 1 Monta~ 15 MT 18036 NA 20464 NA ## 9 1 Unive~ 16 NE 13511 NA 18849 NA ## 10 1 Unive~ 15 NV 10551 NA 17582 NA ## # ... with 256 more rows, and 3 more variables: avgfacsal &lt;int&gt;, ## # unemp_rate &lt;lgl&gt;, year &lt;dbl&gt; F_2017 %&gt;% mutate(year = 2017) ## # A tibble: 266 x 11 ## control instnm ccbasic stabbr npt4_pub npt4_priv costt4_a grad_debt_mdn ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 India~ 16 IN 12021 NA 20352 22343 ## 2 1 Unive~ 15 KS 18814 NA 24824 21105 ## 3 2 Bosto~ 15 MA NA 34550 68039 16939 ## 4 1 Oakla~ 16 MI 12779 NA 21262 25000 ## 5 1 Unive~ 15 MS 13929 NA 23606 19500 ## 6 1 Misso~ 16 MO 14473 NA 22045 24750 ## 7 2 Washi~ 15 MO NA 28540 69754 16075 ## 8 1 Monta~ 15 MT 17754 NA 19980 23500 ## 9 1 Unive~ 16 NE 13173 NA 17935 20250 ## 10 1 Unive~ 15 NV 10555 NA 16964 18750 ## # ... with 256 more rows, and 3 more variables: avgfacsal &lt;int&gt;, ## # unemp_rate &lt;lgl&gt;, year &lt;dbl&gt; F_2016 %&gt;% mutate(year = 2016) ## # A tibble: 266 x 11 ## control instnm ccbasic stabbr npt4_pub npt4_priv costt4_a grad_debt_mdn ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 India~ 16 IN 12417 NA 20451 22668. ## 2 1 Unive~ 15 KS 18234 NA 23687 20500 ## 3 2 Bosto~ 15 MA NA 34356 65595 19000 ## 4 1 Oakla~ 16 MI 12415 NA 20502 25000 ## 5 1 Unive~ 15 MS 14494 NA 23372 19500 ## 6 1 Misso~ 16 MO 14303 NA 21698 24250 ## 7 2 Washi~ 15 MO NA 29957 67751 19500 ## 8 1 Monta~ 15 MT 17050 NA 19441 23505 ## 9 1 Unive~ 16 NE 12899 NA 17712 19500 ## 10 1 Unive~ 15 NV 10726 NA 17131 18500 ## # ... with 256 more rows, and 3 more variables: avgfacsal &lt;int&gt;, ## # unemp_rate &lt;lgl&gt;, year &lt;dbl&gt; F_2015 %&gt;% mutate(year = 2015) ## # A tibble: 266 x 11 ## control instnm ccbasic stabbr npt4_pub npt4_priv costt4_a grad_debt_mdn ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 India~ 16 IN 12861 NA 20257 23000 ## 2 1 Unive~ 15 KS 18755 NA 23733 20454 ## 3 2 Bosto~ 15 MA NA 33661 62968 19000 ## 4 1 Oakla~ 16 MI 11929 NA 19475 25000 ## 5 1 Unive~ 15 MS 14284 NA 22704 19500 ## 6 1 Misso~ 16 MO 14096 NA 21793 24266. ## 7 2 Washi~ 15 MO NA 32873 65887 19500 ## 8 1 Monta~ 15 MT 16809 NA 18961 23683 ## 9 1 Unive~ 16 NE 12505 NA 17148 19032 ## 10 1 Unive~ 15 NV 10915 NA 16791 18750 ## # ... with 256 more rows, and 3 more variables: avgfacsal &lt;int&gt;, ## # unemp_rate &lt;lgl&gt;, year &lt;dbl&gt; Finance &lt;- rbind(F_latest, F_2018, F_2017, F_2016, F_2015) write.csv(Finance, &quot;Proj1Data/Financials15to19.csv&quot;) 2.2.2 Demographics D_latest &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr,female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(&quot;latest&quot;) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! D_2018 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(2018) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! D_2017 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(2017) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! D_2016 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(2016) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! D_2015 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(2015) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! D_latest %&gt;% mutate(year = &quot;latest&quot;) ## # A tibble: 266 x 24 ## control instnm ccbasic stabbr female first_gen poverty_rate veteran ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 India~ 16 IN 0.610 0.351 6.20 0.00394 ## 2 1 Unive~ 15 KS 0.548 0.222 5.24 0.00429 ## 3 2 Bosto~ 15 MA 0.519 0.132 5.93 NA ## 4 1 Oakla~ 16 MI 0.608 0.324 5.74 0.00231 ## 5 1 Unive~ 15 MS 0.608 0.235 12.2 0.00176 ## 6 1 Misso~ 16 MO 0.241 0.225 7.31 NA ## 7 2 Washi~ 15 MO 0.534 0.114 6.17 NA ## 8 1 Monta~ 15 MT 0.493 0.233 8.58 0.00493 ## 9 1 Unive~ 16 NE 0.561 0.348 5.36 0.00304 ## 10 1 Unive~ 15 NV 0.597 0.423 7.25 0.00521 ## # ... with 256 more rows, and 16 more variables: unemp_rate &lt;dbl&gt;, ## # ugds_white &lt;dbl&gt;, ugds_black &lt;dbl&gt;, ugds_hisp &lt;dbl&gt;, ugds_asian &lt;dbl&gt;, ## # ugds_aian &lt;dbl&gt;, ugds_nhpi &lt;dbl&gt;, ugds_2mor &lt;dbl&gt;, ugds_nra &lt;dbl&gt;, ## # ugds_unkn &lt;dbl&gt;, ugds_whitenh &lt;lgl&gt;, ugds_blacknh &lt;lgl&gt;, ugds_api &lt;lgl&gt;, ## # ugds_aianold &lt;lgl&gt;, ugds_hispold &lt;lgl&gt;, year &lt;chr&gt; D_2018 %&gt;% mutate(year = 2018) ## # A tibble: 266 x 24 ## control instnm ccbasic stabbr female first_gen poverty_rate veteran ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 1 India~ 16 IN NA NA NA NA ## 2 1 Unive~ 15 KS NA NA NA NA ## 3 2 Bosto~ 15 MA NA NA NA NA ## 4 1 Oakla~ 16 MI NA NA NA NA ## 5 1 Unive~ 15 MS NA NA NA NA ## 6 1 Misso~ 16 MO NA NA NA NA ## 7 2 Washi~ 15 MO NA NA NA NA ## 8 1 Monta~ 15 MT NA NA NA NA ## 9 1 Unive~ 16 NE NA NA NA NA ## 10 1 Unive~ 15 NV NA NA NA NA ## # ... with 256 more rows, and 16 more variables: unemp_rate &lt;lgl&gt;, ## # ugds_white &lt;dbl&gt;, ugds_black &lt;dbl&gt;, ugds_hisp &lt;dbl&gt;, ugds_asian &lt;dbl&gt;, ## # ugds_aian &lt;dbl&gt;, ugds_nhpi &lt;dbl&gt;, ugds_2mor &lt;dbl&gt;, ugds_nra &lt;dbl&gt;, ## # ugds_unkn &lt;dbl&gt;, ugds_whitenh &lt;lgl&gt;, ugds_blacknh &lt;lgl&gt;, ugds_api &lt;lgl&gt;, ## # ugds_aianold &lt;lgl&gt;, ugds_hispold &lt;lgl&gt;, year &lt;dbl&gt; D_2017 %&gt;% mutate(year = 2017) ## # A tibble: 266 x 24 ## control instnm ccbasic stabbr female first_gen poverty_rate veteran ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 1 India~ 16 IN NA NA NA NA ## 2 1 Unive~ 15 KS NA NA NA NA ## 3 2 Bosto~ 15 MA NA NA NA NA ## 4 1 Oakla~ 16 MI NA NA NA NA ## 5 1 Unive~ 15 MS NA NA NA NA ## 6 1 Misso~ 16 MO NA NA NA NA ## 7 2 Washi~ 15 MO NA NA NA NA ## 8 1 Monta~ 15 MT NA NA NA NA ## 9 1 Unive~ 16 NE NA NA NA NA ## 10 1 Unive~ 15 NV NA NA NA NA ## # ... with 256 more rows, and 16 more variables: unemp_rate &lt;lgl&gt;, ## # ugds_white &lt;dbl&gt;, ugds_black &lt;dbl&gt;, ugds_hisp &lt;dbl&gt;, ugds_asian &lt;dbl&gt;, ## # ugds_aian &lt;dbl&gt;, ugds_nhpi &lt;dbl&gt;, ugds_2mor &lt;dbl&gt;, ugds_nra &lt;dbl&gt;, ## # ugds_unkn &lt;dbl&gt;, ugds_whitenh &lt;lgl&gt;, ugds_blacknh &lt;lgl&gt;, ugds_api &lt;lgl&gt;, ## # ugds_aianold &lt;lgl&gt;, ugds_hispold &lt;lgl&gt;, year &lt;dbl&gt; D_2016 %&gt;% mutate(year = 2016) ## # A tibble: 266 x 24 ## control instnm ccbasic stabbr female first_gen poverty_rate veteran ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; ## 1 1 India~ 16 IN 0.610 0.351 NA 0.00394 ## 2 1 Unive~ 15 KS 0.548 0.222 NA 0.00429 ## 3 2 Bosto~ 15 MA 0.519 0.132 NA NA ## 4 1 Oakla~ 16 MI 0.608 0.324 NA 0.00231 ## 5 1 Unive~ 15 MS 0.608 0.235 NA 0.00176 ## 6 1 Misso~ 16 MO 0.241 0.225 NA NA ## 7 2 Washi~ 15 MO 0.534 0.114 NA NA ## 8 1 Monta~ 15 MT 0.493 0.233 NA 0.00493 ## 9 1 Unive~ 16 NE 0.561 0.348 NA 0.00304 ## 10 1 Unive~ 15 NV 0.597 0.423 NA 0.00521 ## # ... with 256 more rows, and 16 more variables: unemp_rate &lt;lgl&gt;, ## # ugds_white &lt;dbl&gt;, ugds_black &lt;dbl&gt;, ugds_hisp &lt;dbl&gt;, ugds_asian &lt;dbl&gt;, ## # ugds_aian &lt;dbl&gt;, ugds_nhpi &lt;dbl&gt;, ugds_2mor &lt;dbl&gt;, ugds_nra &lt;dbl&gt;, ## # ugds_unkn &lt;dbl&gt;, ugds_whitenh &lt;lgl&gt;, ugds_blacknh &lt;lgl&gt;, ugds_api &lt;lgl&gt;, ## # ugds_aianold &lt;lgl&gt;, ugds_hispold &lt;lgl&gt;, year &lt;dbl&gt; D_2015 %&gt;% mutate(year = 2015) ## # A tibble: 266 x 24 ## control instnm ccbasic stabbr female first_gen poverty_rate veteran ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;dbl&gt; ## 1 1 India~ 16 IN 0.607 0.361 NA 0.00390 ## 2 1 Unive~ 15 KS 0.536 0.226 NA 0.00534 ## 3 2 Bosto~ 15 MA 0.532 0.125 NA NA ## 4 1 Oakla~ 16 MI 0.599 0.325 NA 0.00207 ## 5 1 Unive~ 15 MS 0.613 0.226 NA 0.00209 ## 6 1 Misso~ 16 MO 0.228 0.226 NA NA ## 7 2 Washi~ 15 MO 0.541 0.0897 NA NA ## 8 1 Monta~ 15 MT 0.492 0.231 NA 0.00589 ## 9 1 Unive~ 16 NE 0.55 0.337 NA 0.00492 ## 10 1 Unive~ 15 NV 0.586 0.419 NA 0.00573 ## # ... with 256 more rows, and 16 more variables: unemp_rate &lt;lgl&gt;, ## # ugds_white &lt;dbl&gt;, ugds_black &lt;dbl&gt;, ugds_hisp &lt;dbl&gt;, ugds_asian &lt;dbl&gt;, ## # ugds_aian &lt;dbl&gt;, ugds_nhpi &lt;dbl&gt;, ugds_2mor &lt;dbl&gt;, ugds_nra &lt;dbl&gt;, ## # ugds_unkn &lt;dbl&gt;, ugds_whitenh &lt;lgl&gt;, ugds_blacknh &lt;lgl&gt;, ugds_api &lt;lgl&gt;, ## # ugds_aianold &lt;lgl&gt;, ugds_hispold &lt;lgl&gt;, year &lt;dbl&gt; Demographics &lt;- rbind(D_latest, D_2018, D_2017, D_2016, D_2015) write.csv(Demographics, &quot;Proj1Data/Demographics15to19.csv&quot;) 2.2.3 Death Dth_latest &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(&quot;latest&quot;) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! Dth_2018 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr,death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(2018) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! Dth_2017 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(2017) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! Dth_2016 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(2016) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! Dth_2015 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(2015) %&gt;% sc_get() ## Large request will require: 2 additional pulls. ## Request chunk 1 ## Request chunk 2 ## Request complete! Dth_latest %&gt;% mutate(year = &quot;latest&quot;) ## # A tibble: 266 x 25 ## control instnm ccbasic stabbr death_yr2_rt lo_inc_death_yr~ md_inc_death_yr~ ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 1 India~ 16 IN NA NA NA ## 2 1 Unive~ 15 KS NA NA NA ## 3 2 Bosto~ 15 MA NA NA NA ## 4 1 Oakla~ 16 MI NA NA NA ## 5 1 Unive~ 15 MS NA NA NA ## 6 1 Misso~ 16 MO NA NA NA ## 7 2 Washi~ 15 MO NA NA NA ## 8 1 Monta~ 15 MT NA NA NA ## 9 1 Unive~ 16 NE NA NA NA ## 10 1 Unive~ 15 NV NA NA NA ## # ... with 256 more rows, and 18 more variables: hi_inc_death_yr2_rt &lt;lgl&gt;, ## # death_yr3_rt &lt;dbl&gt;, lo_inc_death_yr3_rt &lt;lgl&gt;, md_inc_death_yr3_rt &lt;lgl&gt;, ## # hi_inc_death_yr3_rt &lt;lgl&gt;, death_yr4_rt &lt;dbl&gt;, lo_inc_death_yr4_rt &lt;dbl&gt;, ## # md_inc_death_yr4_rt &lt;dbl&gt;, hi_inc_death_yr4_rt &lt;lgl&gt;, death_yr6_rt &lt;dbl&gt;, ## # lo_inc_death_yr6_rt &lt;dbl&gt;, md_inc_death_yr6_rt &lt;dbl&gt;, ## # hi_inc_death_yr6_rt &lt;lgl&gt;, death_yr8_rt &lt;dbl&gt;, lo_inc_death_yr8_rt &lt;dbl&gt;, ## # md_inc_death_yr8_rt &lt;dbl&gt;, hi_inc_death_yr8_rt &lt;lgl&gt;, year &lt;chr&gt; Dth_2018 %&gt;% mutate(year = 2018) ## # A tibble: 266 x 25 ## control instnm ccbasic stabbr death_yr2_rt lo_inc_death_yr~ md_inc_death_yr~ ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 1 India~ 16 IN NA NA NA ## 2 1 Unive~ 15 KS NA NA NA ## 3 2 Bosto~ 15 MA NA NA NA ## 4 1 Oakla~ 16 MI NA NA NA ## 5 1 Unive~ 15 MS NA NA NA ## 6 1 Misso~ 16 MO NA NA NA ## 7 2 Washi~ 15 MO NA NA NA ## 8 1 Monta~ 15 MT NA NA NA ## 9 1 Unive~ 16 NE NA NA NA ## 10 1 Unive~ 15 NV NA NA NA ## # ... with 256 more rows, and 18 more variables: hi_inc_death_yr2_rt &lt;lgl&gt;, ## # death_yr3_rt &lt;lgl&gt;, lo_inc_death_yr3_rt &lt;lgl&gt;, md_inc_death_yr3_rt &lt;lgl&gt;, ## # hi_inc_death_yr3_rt &lt;lgl&gt;, death_yr4_rt &lt;lgl&gt;, lo_inc_death_yr4_rt &lt;lgl&gt;, ## # md_inc_death_yr4_rt &lt;lgl&gt;, hi_inc_death_yr4_rt &lt;lgl&gt;, death_yr6_rt &lt;lgl&gt;, ## # lo_inc_death_yr6_rt &lt;lgl&gt;, md_inc_death_yr6_rt &lt;lgl&gt;, ## # hi_inc_death_yr6_rt &lt;lgl&gt;, death_yr8_rt &lt;lgl&gt;, lo_inc_death_yr8_rt &lt;lgl&gt;, ## # md_inc_death_yr8_rt &lt;lgl&gt;, hi_inc_death_yr8_rt &lt;lgl&gt;, year &lt;dbl&gt; Dth_2017 %&gt;% mutate(year = 2017) ## # A tibble: 266 x 25 ## control instnm ccbasic stabbr death_yr2_rt lo_inc_death_yr~ md_inc_death_yr~ ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 1 India~ 16 IN NA NA NA ## 2 1 Unive~ 15 KS NA NA NA ## 3 2 Bosto~ 15 MA NA NA NA ## 4 1 Oakla~ 16 MI NA NA NA ## 5 1 Unive~ 15 MS NA NA NA ## 6 1 Misso~ 16 MO NA NA NA ## 7 2 Washi~ 15 MO NA NA NA ## 8 1 Monta~ 15 MT NA NA NA ## 9 1 Unive~ 16 NE NA NA NA ## 10 1 Unive~ 15 NV NA NA NA ## # ... with 256 more rows, and 18 more variables: hi_inc_death_yr2_rt &lt;lgl&gt;, ## # death_yr3_rt &lt;lgl&gt;, lo_inc_death_yr3_rt &lt;lgl&gt;, md_inc_death_yr3_rt &lt;lgl&gt;, ## # hi_inc_death_yr3_rt &lt;lgl&gt;, death_yr4_rt &lt;lgl&gt;, lo_inc_death_yr4_rt &lt;lgl&gt;, ## # md_inc_death_yr4_rt &lt;lgl&gt;, hi_inc_death_yr4_rt &lt;lgl&gt;, death_yr6_rt &lt;lgl&gt;, ## # lo_inc_death_yr6_rt &lt;lgl&gt;, md_inc_death_yr6_rt &lt;lgl&gt;, ## # hi_inc_death_yr6_rt &lt;lgl&gt;, death_yr8_rt &lt;lgl&gt;, lo_inc_death_yr8_rt &lt;lgl&gt;, ## # md_inc_death_yr8_rt &lt;lgl&gt;, hi_inc_death_yr8_rt &lt;lgl&gt;, year &lt;dbl&gt; Dth_2016 %&gt;% mutate(year = 2016) ## # A tibble: 266 x 25 ## control instnm ccbasic stabbr death_yr2_rt lo_inc_death_yr~ md_inc_death_yr~ ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 1 India~ 16 IN NA NA NA ## 2 1 Unive~ 15 KS NA NA NA ## 3 2 Bosto~ 15 MA NA NA NA ## 4 1 Oakla~ 16 MI NA NA NA ## 5 1 Unive~ 15 MS NA NA NA ## 6 1 Misso~ 16 MO NA NA NA ## 7 2 Washi~ 15 MO NA NA NA ## 8 1 Monta~ 15 MT NA NA NA ## 9 1 Unive~ 16 NE NA NA NA ## 10 1 Unive~ 15 NV NA NA NA ## # ... with 256 more rows, and 18 more variables: hi_inc_death_yr2_rt &lt;lgl&gt;, ## # death_yr3_rt &lt;dbl&gt;, lo_inc_death_yr3_rt &lt;lgl&gt;, md_inc_death_yr3_rt &lt;lgl&gt;, ## # hi_inc_death_yr3_rt &lt;lgl&gt;, death_yr4_rt &lt;dbl&gt;, lo_inc_death_yr4_rt &lt;dbl&gt;, ## # md_inc_death_yr4_rt &lt;dbl&gt;, hi_inc_death_yr4_rt &lt;lgl&gt;, death_yr6_rt &lt;dbl&gt;, ## # lo_inc_death_yr6_rt &lt;dbl&gt;, md_inc_death_yr6_rt &lt;dbl&gt;, ## # hi_inc_death_yr6_rt &lt;lgl&gt;, death_yr8_rt &lt;dbl&gt;, lo_inc_death_yr8_rt &lt;dbl&gt;, ## # md_inc_death_yr8_rt &lt;dbl&gt;, hi_inc_death_yr8_rt &lt;lgl&gt;, year &lt;dbl&gt; Dth_2015 %&gt;% mutate(year = 2015) ## # A tibble: 266 x 25 ## control instnm ccbasic stabbr death_yr2_rt lo_inc_death_yr~ md_inc_death_yr~ ## &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 1 India~ 16 IN NA NA NA ## 2 1 Unive~ 15 KS NA NA NA ## 3 2 Bosto~ 15 MA NA NA NA ## 4 1 Oakla~ 16 MI NA NA NA ## 5 1 Unive~ 15 MS NA NA NA ## 6 1 Misso~ 16 MO NA NA NA ## 7 2 Washi~ 15 MO NA NA NA ## 8 1 Monta~ 15 MT NA NA NA ## 9 1 Unive~ 16 NE NA NA NA ## 10 1 Unive~ 15 NV NA NA NA ## # ... with 256 more rows, and 18 more variables: hi_inc_death_yr2_rt &lt;lgl&gt;, ## # death_yr3_rt &lt;dbl&gt;, lo_inc_death_yr3_rt &lt;lgl&gt;, md_inc_death_yr3_rt &lt;lgl&gt;, ## # hi_inc_death_yr3_rt &lt;lgl&gt;, death_yr4_rt &lt;dbl&gt;, lo_inc_death_yr4_rt &lt;lgl&gt;, ## # md_inc_death_yr4_rt &lt;lgl&gt;, hi_inc_death_yr4_rt &lt;lgl&gt;, death_yr6_rt &lt;dbl&gt;, ## # lo_inc_death_yr6_rt &lt;dbl&gt;, md_inc_death_yr6_rt &lt;lgl&gt;, ## # hi_inc_death_yr6_rt &lt;lgl&gt;, death_yr8_rt &lt;dbl&gt;, lo_inc_death_yr8_rt &lt;dbl&gt;, ## # md_inc_death_yr8_rt &lt;lgl&gt;, hi_inc_death_yr8_rt &lt;lgl&gt;, year &lt;dbl&gt; Death &lt;- rbind(Dth_latest, Dth_2018, Dth_2017, Dth_2016, Dth_2015) write.csv(Death, &quot;Proj1Data/Death15to19.csv&quot;) R1Schools &lt;- sc_init() %&gt;% sc_filter(ccbasic == 15) %&gt;% sc_select(control, instnm, stabbr) %&gt;% sc_year(&quot;latest&quot;) %&gt;% sc_get() ## Large request will require: 1 additional pulls. ## Request chunk 1 ## Request complete! #install.packages(&quot;maps&quot;) library(maps) ## ## Attaching package: &#39;maps&#39; ## The following object is masked from &#39;package:purrr&#39;: ## ## map ## The following object is masked from &#39;package:plyr&#39;: ## ## ozone library(usmap) debtMedian &lt;- Finance %&gt;% group_by(stabbr) %&gt;% mutate(avgDebt = mean(grad_debt_mdn, na.rm = TRUE)) %&gt;% select(stabbr, avgDebt)%&gt;% filter(stabbr %notin% c(&#39;PR&#39;,&#39;DC&#39;)) %&gt;% ungroup() debtMedian &lt;- as.data.frame(debtMedian) colnames(debtMedian) &lt;- c(&quot;state&quot;, &quot;avgDebt&quot;) debtMedian[1] ## state ## 1 IN ## 2 KS ## 3 MA ## 4 MI ## 5 MS ## 6 MO ## 7 MO ## 8 MT ## 9 NE ## 10 NV ## 11 CO ## 12 CA ## 13 CT ## 14 DE ## 15 FL ## 16 FL ## 17 FL ## 18 HI ## 19 GA ## 20 GA ## 21 OR ## 22 TN ## 23 TX ## 24 TX ## 25 TX ## 26 TX ## 27 CA ## 28 CA ## 29 FL ## 30 GA ## 31 IL ## 32 IL ## 33 IN ## 34 LA ## 35 LA ## 36 VA ## 37 WA ## 38 WV ## 39 WV ## 40 AL ## 41 AK ## 42 AL ## 43 AR ## 44 CA ## 45 CA ## 46 CA ## 47 SC ## 48 TN ## 49 TN ## 50 TX ## 51 TX ## 52 UT ## 53 WI ## 54 ME ## 55 MA ## 56 MA ## 57 MA ## 58 MA ## 59 NY ## 60 NY ## 61 NC ## 62 OH ## 63 CA ## 64 NY ## 65 NY ## 66 NY ## 67 NY ## 68 NC ## 69 OH ## 70 ND ## 71 MI ## 72 NE ## 73 NH ## 74 AZ ## 75 NJ ## 76 NJ ## 77 NJ ## 78 NJ ## 79 OK ## 80 PA ## 81 UT ## 82 VA ## 83 NC ## 84 OH ## 85 OH ## 86 OH ## 87 CA ## 88 CA ## 89 CA ## 90 CA ## 91 CO ## 92 KY ## 93 MI ## 94 NJ ## 95 NM ## 96 FL ## 97 ID ## 98 KS ## 99 LA ## 100 LA ## 101 MD ## 102 MD ## 103 MD ## 104 IL ## 105 IL ## 106 IA ## 107 GA ## 108 GA ## 109 ID ## 110 MA ## 111 MA ## 112 MA ## 113 MI ## 114 MI ## 115 MA ## 116 MA ## 117 AL ## 118 AR ## 119 AR ## 120 CA ## 121 CO ## 122 CO ## 123 AZ ## 124 OK ## 125 PA ## 126 TX ## 127 TX ## 128 TX ## 129 TX ## 130 TX ## 131 VT ## 132 MS ## 133 MO ## 134 NJ ## 135 NY ## 136 NY ## 137 NY ## 138 NY ## 139 NC ## 140 NC ## 141 OH ## 142 OH ## 143 OH ## 144 OH ## 145 OH ## 146 OR ## 147 OR ## 148 PA ## 149 PA ## 150 TN ## 151 WY ## 152 WI ## 153 CA ## 154 VA ## 155 UT ## 156 VA ## 157 RI ## 158 SD ## 159 OK ## 160 PA ## 161 PA ## 162 PA ## 163 TN ## 164 NJ ## 165 NM ## 166 NY ## 167 NY ## 168 NY ## 169 NY ## 170 TN ## 171 TX ## 172 TX ## 173 TX ## 174 TX ## 175 VA ## 176 WA ## 177 KS ## 178 KY ## 179 ME ## 180 MD ## 181 MD ## 182 MA ## 183 MA ## 184 OH ## 185 PA ## 186 CO ## 187 CT ## 188 FL ## 189 FL ## 190 FL ## 191 DE ## 192 NJ ## 193 NJ ## 194 NY ## 195 PA ## 196 PA ## 197 RI ## 198 SC ## 199 SD ## 200 MO ## 201 MO ## 202 MO ## 203 MT ## 204 NH ## 205 NC ## 206 NC ## 207 GA ## 208 FL ## 209 ID ## 210 IL ## 211 IL ## 212 IL ## 213 IN ## 214 GA ## 215 GA ## 216 IL ## 217 IL ## 218 IN ## 219 IA ## 220 CA ## 221 CA ## 222 CA ## 223 CO ## 224 FL ## 225 IL ## 226 LA ## 227 MN ## 228 MI ## 229 MA ## 230 MI ## 231 MI ## 232 MS ## 233 MS ## 234 NV ## 235 NY ## 236 NY ## 237 NY ## 238 NY ## 239 NY ## 240 NC ## 241 NC ## 242 AZ ## 243 OH ## 244 ND ## 245 TX ## 246 TX ## 247 TX ## 248 VA ## 249 VA ## 250 WI ## 251 IN ## 252 AZ ## 253 AZ ## 254 CA ## 255 CA ## 256 OH ## 257 AL ## 258 AL ## 259 IN ## 260 KS ## 261 MA ## 262 MI ## 263 MS ## 264 MO ## 265 MO ## 266 MT ## 267 NE ## 268 NV ## 269 CO ## 270 CA ## 271 CT ## 272 DE ## 273 FL ## 274 FL ## 275 FL ## 276 HI ## 277 GA ## 278 GA ## 279 OR ## 280 TN ## 281 TX ## 282 TX ## 283 TX ## 284 TX ## 285 CA ## 286 CA ## 287 FL ## 288 GA ## 289 IL ## 290 IL ## 291 IN ## 292 LA ## 293 LA ## 294 VA ## 295 WA ## 296 WV ## 297 WV ## 298 AL ## 299 AK ## 300 AL ## 301 AR ## 302 CA ## 303 CA ## 304 CA ## 305 SC ## 306 TN ## 307 TN ## 308 TX ## 309 TX ## 310 UT ## 311 WI ## 312 ME ## 313 MA ## 314 MA ## 315 MA ## 316 MA ## 317 NY ## 318 NY ## 319 NC ## 320 OH ## 321 CA ## 322 NY ## 323 NY ## 324 NY ## 325 NY ## 326 NC ## 327 OH ## 328 ND ## 329 MI ## 330 NE ## 331 NH ## 332 AZ ## 333 NJ ## 334 NJ ## 335 NJ ## 336 NJ ## 337 OK ## 338 PA ## 339 UT ## 340 VA ## 341 NC ## 342 OH ## 343 OH ## 344 OH ## 345 CA ## 346 CA ## 347 CA ## 348 CA ## 349 CO ## 350 KY ## 351 MI ## 352 NJ ## 353 NM ## 354 FL ## 355 ID ## 356 KS ## 357 LA ## 358 LA ## 359 MD ## 360 MD ## 361 MD ## 362 IL ## 363 IL ## 364 IA ## 365 GA ## 366 GA ## 367 ID ## 368 MA ## 369 MA ## 370 MA ## 371 MI ## 372 MI ## 373 MA ## 374 MA ## 375 AL ## 376 AR ## 377 AR ## 378 CA ## 379 CO ## 380 CO ## 381 AZ ## 382 OK ## 383 PA ## 384 TX ## 385 TX ## 386 TX ## 387 TX ## 388 TX ## 389 VT ## 390 MS ## 391 MO ## 392 NJ ## 393 NY ## 394 NY ## 395 NY ## 396 NY ## 397 NC ## 398 NC ## 399 OH ## 400 OH ## 401 OH ## 402 OH ## 403 OH ## 404 OR ## 405 OR ## 406 PA ## 407 PA ## 408 TN ## 409 WY ## 410 WI ## 411 CA ## 412 VA ## 413 UT ## 414 VA ## 415 RI ## 416 SD ## 417 OK ## 418 PA ## 419 PA ## 420 PA ## 421 TN ## 422 NJ ## 423 NM ## 424 NY ## 425 NY ## 426 NY ## 427 NY ## 428 TN ## 429 TX ## 430 TX ## 431 TX ## 432 TX ## 433 VA ## 434 WA ## 435 KS ## 436 KY ## 437 ME ## 438 MD ## 439 MD ## 440 MA ## 441 MA ## 442 OH ## 443 PA ## 444 CO ## 445 CT ## 446 FL ## 447 FL ## 448 FL ## 449 DE ## 450 NJ ## 451 NJ ## 452 NY ## 453 PA ## 454 PA ## 455 RI ## 456 SC ## 457 SD ## 458 MO ## 459 MO ## 460 MO ## 461 MT ## 462 NH ## 463 NC ## 464 NC ## 465 GA ## 466 FL ## 467 ID ## 468 IL ## 469 IL ## 470 IL ## 471 IN ## 472 GA ## 473 GA ## 474 IL ## 475 IL ## 476 IN ## 477 IA ## 478 CA ## 479 CA ## 480 CA ## 481 CO ## 482 FL ## 483 IL ## 484 LA ## 485 MN ## 486 MI ## 487 MA ## 488 MI ## 489 MI ## 490 MS ## 491 MS ## 492 NV ## 493 NY ## 494 NY ## 495 NY ## 496 NY ## 497 NY ## 498 NC ## 499 NC ## 500 AZ ## 501 OH ## 502 ND ## 503 TX ## 504 TX ## 505 TX ## 506 VA ## 507 VA ## 508 WI ## 509 IN ## 510 AZ ## 511 AZ ## 512 CA ## 513 CA ## 514 OH ## 515 AL ## 516 AL ## 517 IN ## 518 KS ## 519 MA ## 520 MI ## 521 MS ## 522 MO ## 523 MO ## 524 MT ## 525 NE ## 526 NV ## 527 CO ## 528 CA ## 529 CT ## 530 DE ## 531 FL ## 532 FL ## 533 FL ## 534 HI ## 535 GA ## 536 GA ## 537 OR ## 538 TN ## 539 TX ## 540 TX ## 541 TX ## 542 TX ## 543 CA ## 544 CA ## 545 FL ## 546 GA ## 547 IL ## 548 IL ## 549 IN ## 550 LA ## 551 LA ## 552 VA ## 553 WA ## 554 WV ## 555 WV ## 556 AL ## 557 AK ## 558 AL ## 559 AR ## 560 CA ## 561 CA ## 562 CA ## 563 SC ## 564 TN ## 565 TN ## 566 TX ## 567 TX ## 568 UT ## 569 WI ## 570 ME ## 571 MA ## 572 MA ## 573 MA ## 574 MA ## 575 NY ## 576 NY ## 577 NC ## 578 OH ## 579 CA ## 580 NY ## 581 NY ## 582 NY ## 583 NY ## 584 NC ## 585 OH ## 586 ND ## 587 MI ## 588 NE ## 589 NH ## 590 AZ ## 591 NJ ## 592 NJ ## 593 NJ ## 594 NJ ## 595 OK ## 596 PA ## 597 UT ## 598 VA ## 599 NC ## 600 OH ## 601 OH ## 602 OH ## 603 CA ## 604 CA ## 605 CA ## 606 CA ## 607 CO ## 608 KY ## 609 MI ## 610 NJ ## 611 NM ## 612 FL ## 613 ID ## 614 KS ## 615 LA ## 616 LA ## 617 MD ## 618 MD ## 619 MD ## 620 IL ## 621 IL ## 622 IA ## 623 GA ## 624 GA ## 625 ID ## 626 MA ## 627 MA ## 628 MA ## 629 MI ## 630 MI ## 631 MA ## 632 MA ## 633 AL ## 634 AR ## 635 AR ## 636 CA ## 637 CO ## 638 CO ## 639 AZ ## 640 OK ## 641 PA ## 642 TX ## 643 TX ## 644 TX ## 645 TX ## 646 TX ## 647 VT ## 648 MS ## 649 MO ## 650 NJ ## 651 NY ## 652 NY ## 653 NY ## 654 NY ## 655 NC ## 656 NC ## 657 OH ## 658 OH ## 659 OH ## 660 OH ## 661 OH ## 662 OR ## 663 OR ## 664 PA ## 665 PA ## 666 TN ## 667 WY ## 668 WI ## 669 CA ## 670 VA ## 671 UT ## 672 VA ## 673 RI ## 674 SD ## 675 OK ## 676 PA ## 677 PA ## 678 PA ## 679 TN ## 680 NJ ## 681 NM ## 682 NY ## 683 NY ## 684 NY ## 685 NY ## 686 TN ## 687 TX ## 688 TX ## 689 TX ## 690 TX ## 691 VA ## 692 WA ## 693 KS ## 694 KY ## 695 ME ## 696 MD ## 697 MD ## 698 MA ## 699 MA ## 700 OH ## 701 PA ## 702 CO ## 703 CT ## 704 FL ## 705 FL ## 706 FL ## 707 DE ## 708 NJ ## 709 NJ ## 710 NY ## 711 PA ## 712 PA ## 713 RI ## 714 SC ## 715 SD ## 716 MO ## 717 MO ## 718 MO ## 719 MT ## 720 NH ## 721 NC ## 722 NC ## 723 GA ## 724 FL ## 725 ID ## 726 IL ## 727 IL ## 728 IL ## 729 IN ## 730 GA ## 731 GA ## 732 IL ## 733 IL ## 734 IN ## 735 IA ## 736 CA ## 737 CA ## 738 CA ## 739 CO ## 740 FL ## 741 IL ## 742 LA ## 743 MN ## 744 MI ## 745 MA ## 746 MI ## 747 MI ## 748 MS ## 749 MS ## 750 NV ## 751 NY ## 752 NY ## 753 NY ## 754 NY ## 755 NY ## 756 NC ## 757 NC ## 758 AZ ## 759 OH ## 760 ND ## 761 TX ## 762 TX ## 763 TX ## 764 VA ## 765 VA ## 766 WI ## 767 IN ## 768 AZ ## 769 AZ ## 770 CA ## 771 CA ## 772 OH ## 773 AL ## 774 AL ## 775 IN ## 776 KS ## 777 MA ## 778 MI ## 779 MS ## 780 MO ## 781 MO ## 782 MT ## 783 NE ## 784 NV ## 785 CO ## 786 CA ## 787 CT ## 788 DE ## 789 FL ## 790 FL ## 791 FL ## 792 HI ## 793 GA ## 794 GA ## 795 OR ## 796 TN ## 797 TX ## 798 TX ## 799 TX ## 800 TX ## 801 CA ## 802 CA ## 803 FL ## 804 GA ## 805 IL ## 806 IL ## 807 IN ## 808 LA ## 809 LA ## 810 VA ## 811 WA ## 812 WV ## 813 WV ## 814 AL ## 815 AK ## 816 AL ## 817 AR ## 818 CA ## 819 CA ## 820 CA ## 821 SC ## 822 TN ## 823 TN ## 824 TX ## 825 TX ## 826 UT ## 827 WI ## 828 ME ## 829 MA ## 830 MA ## 831 MA ## 832 MA ## 833 NY ## 834 NY ## 835 NC ## 836 OH ## 837 CA ## 838 NY ## 839 NY ## 840 NY ## 841 NY ## 842 NC ## 843 OH ## 844 ND ## 845 MI ## 846 NE ## 847 NH ## 848 AZ ## 849 NJ ## 850 NJ ## 851 NJ ## 852 NJ ## 853 OK ## 854 PA ## 855 UT ## 856 VA ## 857 NC ## 858 OH ## 859 OH ## 860 OH ## 861 CA ## 862 CA ## 863 CA ## 864 CA ## 865 CO ## 866 KY ## 867 MI ## 868 NJ ## 869 NM ## 870 FL ## 871 ID ## 872 KS ## 873 LA ## 874 LA ## 875 MD ## 876 MD ## 877 MD ## 878 IL ## 879 IL ## 880 IA ## 881 GA ## 882 GA ## 883 ID ## 884 MA ## 885 MA ## 886 MA ## 887 MI ## 888 MI ## 889 MA ## 890 MA ## 891 AL ## 892 AR ## 893 AR ## 894 CA ## 895 CO ## 896 CO ## 897 AZ ## 898 OK ## 899 PA ## 900 TX ## 901 TX ## 902 TX ## 903 TX ## 904 TX ## 905 VT ## 906 MS ## 907 MO ## 908 NJ ## 909 NY ## 910 NY ## 911 NY ## 912 NY ## 913 NC ## 914 NC ## 915 OH ## 916 OH ## 917 OH ## 918 OH ## 919 OH ## 920 OR ## 921 OR ## 922 PA ## 923 PA ## 924 TN ## 925 WY ## 926 WI ## 927 CA ## 928 VA ## 929 UT ## 930 VA ## 931 RI ## 932 SD ## 933 OK ## 934 PA ## 935 PA ## 936 PA ## 937 TN ## 938 NJ ## 939 NM ## 940 NY ## 941 NY ## 942 NY ## 943 NY ## 944 TN ## 945 TX ## 946 TX ## 947 TX ## 948 TX ## 949 VA ## 950 WA ## 951 KS ## 952 KY ## 953 ME ## 954 MD ## 955 MD ## 956 MA ## 957 MA ## 958 OH ## 959 PA ## 960 CO ## 961 CT ## 962 FL ## 963 FL ## 964 FL ## 965 DE ## 966 NJ ## 967 NJ ## 968 NY ## 969 PA ## 970 PA ## 971 RI ## 972 SC ## 973 SD ## 974 MO ## 975 MO ## 976 MO ## 977 MT ## 978 NH ## 979 NC ## 980 NC ## 981 GA ## 982 FL ## 983 ID ## 984 IL ## 985 IL ## 986 IL ## 987 IN ## 988 GA ## 989 GA ## 990 IL ## 991 IL ## 992 IN ## 993 IA ## 994 CA ## 995 CA ## 996 CA ## 997 CO ## 998 FL ## 999 IL ## 1000 LA ## 1001 MN ## 1002 MI ## 1003 MA ## 1004 MI ## 1005 MI ## 1006 MS ## 1007 MS ## 1008 NV ## 1009 NY ## 1010 NY ## 1011 NY ## 1012 NY ## 1013 NY ## 1014 NC ## 1015 NC ## 1016 AZ ## 1017 OH ## 1018 ND ## 1019 TX ## 1020 TX ## 1021 TX ## 1022 VA ## 1023 VA ## 1024 WI ## 1025 IN ## 1026 AZ ## 1027 AZ ## 1028 CA ## 1029 CA ## 1030 OH ## 1031 AL ## 1032 AL ## 1033 IN ## 1034 KS ## 1035 MA ## 1036 MI ## 1037 MS ## 1038 MO ## 1039 MO ## 1040 MT ## 1041 NE ## 1042 NV ## 1043 CO ## 1044 CA ## 1045 CT ## 1046 DE ## 1047 FL ## 1048 FL ## 1049 FL ## 1050 HI ## 1051 GA ## 1052 GA ## 1053 OR ## 1054 TN ## 1055 TX ## 1056 TX ## 1057 TX ## 1058 TX ## 1059 CA ## 1060 CA ## 1061 FL ## 1062 GA ## 1063 IL ## 1064 IL ## 1065 IN ## 1066 LA ## 1067 LA ## 1068 VA ## 1069 WA ## 1070 WV ## 1071 WV ## 1072 AL ## 1073 AK ## 1074 AL ## 1075 AR ## 1076 CA ## 1077 CA ## 1078 CA ## 1079 SC ## 1080 TN ## 1081 TN ## 1082 TX ## 1083 TX ## 1084 UT ## 1085 WI ## 1086 ME ## 1087 MA ## 1088 MA ## 1089 MA ## 1090 MA ## 1091 NY ## 1092 NY ## 1093 NC ## 1094 OH ## 1095 CA ## 1096 NY ## 1097 NY ## 1098 NY ## 1099 NY ## 1100 NC ## 1101 OH ## 1102 ND ## 1103 MI ## 1104 NE ## 1105 NH ## 1106 AZ ## 1107 NJ ## 1108 NJ ## 1109 NJ ## 1110 NJ ## 1111 OK ## 1112 PA ## 1113 UT ## 1114 VA ## 1115 NC ## 1116 OH ## 1117 OH ## 1118 OH ## 1119 CA ## 1120 CA ## 1121 CA ## 1122 CA ## 1123 CO ## 1124 KY ## 1125 MI ## 1126 NJ ## 1127 NM ## 1128 FL ## 1129 ID ## 1130 KS ## 1131 LA ## 1132 LA ## 1133 MD ## 1134 MD ## 1135 MD ## 1136 IL ## 1137 IL ## 1138 IA ## 1139 GA ## 1140 GA ## 1141 ID ## 1142 MA ## 1143 MA ## 1144 MA ## 1145 MI ## 1146 MI ## 1147 MA ## 1148 MA ## 1149 AL ## 1150 AR ## 1151 AR ## 1152 CA ## 1153 CO ## 1154 CO ## 1155 AZ ## 1156 OK ## 1157 PA ## 1158 TX ## 1159 TX ## 1160 TX ## 1161 TX ## 1162 TX ## 1163 VT ## 1164 MS ## 1165 MO ## 1166 NJ ## 1167 NY ## 1168 NY ## 1169 NY ## 1170 NY ## 1171 NC ## 1172 NC ## 1173 OH ## 1174 OH ## 1175 OH ## 1176 OH ## 1177 OH ## 1178 OR ## 1179 OR ## 1180 PA ## 1181 PA ## 1182 TN ## 1183 WY ## 1184 WI ## 1185 CA ## 1186 VA ## 1187 UT ## 1188 VA ## 1189 RI ## 1190 SD ## 1191 OK ## 1192 PA ## 1193 PA ## 1194 PA ## 1195 TN ## 1196 NJ ## 1197 NM ## 1198 NY ## 1199 NY ## 1200 NY ## 1201 NY ## 1202 TN ## 1203 TX ## 1204 TX ## 1205 TX ## 1206 TX ## 1207 VA ## 1208 WA ## 1209 KS ## 1210 KY ## 1211 ME ## 1212 MD ## 1213 MD ## 1214 MA ## 1215 MA ## 1216 OH ## 1217 PA ## 1218 CO ## 1219 CT ## 1220 FL ## 1221 FL ## 1222 FL ## 1223 DE ## 1224 NJ ## 1225 NJ ## 1226 NY ## 1227 PA ## 1228 PA ## 1229 RI ## 1230 SC ## 1231 SD ## 1232 MO ## 1233 MO ## 1234 MO ## 1235 MT ## 1236 NH ## 1237 NC ## 1238 NC ## 1239 GA ## 1240 FL ## 1241 ID ## 1242 IL ## 1243 IL ## 1244 IL ## 1245 IN ## 1246 GA ## 1247 GA ## 1248 IL ## 1249 IL ## 1250 IN ## 1251 IA ## 1252 CA ## 1253 CA ## 1254 CA ## 1255 CO ## 1256 FL ## 1257 IL ## 1258 LA ## 1259 MN ## 1260 MI ## 1261 MA ## 1262 MI ## 1263 MI ## 1264 MS ## 1265 MS ## 1266 NV ## 1267 NY ## 1268 NY ## 1269 NY ## 1270 NY ## 1271 NY ## 1272 NC ## 1273 NC ## 1274 AZ ## 1275 OH ## 1276 ND ## 1277 TX ## 1278 TX ## 1279 TX ## 1280 VA ## 1281 VA ## 1282 WI ## 1283 IN ## 1284 AZ ## 1285 AZ ## 1286 CA ## 1287 CA ## 1288 OH ## 1289 AL ## 1290 AL plot_usmap(data =debtMedian, values = &quot;avgDebt&quot;, color = &quot;black&quot;) + scale_fill_continuous( low = &quot;white&quot;, high = &quot;red&quot;, name = &quot;Average Debt Median&quot;, label = scales::comma ) + theme(legend.position = &quot;right&quot;) ## Warning: Use of `map_df$x` is discouraged. Use `x` instead. ## Warning: Use of `map_df$y` is discouraged. Use `y` instead. ## Warning: Use of `map_df$group` is discouraged. Use `group` instead. FacSalary &lt;- Finance %&gt;% group_by(stabbr) %&gt;% mutate(avgSal = mean(avgfacsal, na.rm = TRUE)) %&gt;% select(stabbr, avgSal) %&gt;% filter(stabbr %notin% c(&#39;PR&#39;,&#39;DC&#39;)) %&gt;% ungroup() FacSalary &lt;- as.data.frame(FacSalary) colnames(FacSalary) &lt;- c(&quot;state&quot;, &quot;avgSal&quot;) plot_usmap(data =FacSalary, values = &quot;avgSal&quot;, color = &quot;black&quot;) + scale_fill_continuous(low = &quot;white&quot;, high = &quot;blue&quot;, name = &quot;Average Faculty Salary&quot;, label = scales::comma) + theme(legend.position = &quot;right&quot;) ## Warning: Use of `map_df$x` is discouraged. Use `x` instead. ## Warning: Use of `map_df$y` is discouraged. Use `y` instead. ## Warning: Use of `map_df$group` is discouraged. Use `group` instead. Finance %&gt;% filter(year == &quot;lastest&quot;) ## # A tibble: 0 x 11 ## # ... with 11 variables: control &lt;int&gt;, instnm &lt;chr&gt;, ccbasic &lt;int&gt;, ## # stabbr &lt;chr&gt;, npt4_pub &lt;int&gt;, npt4_priv &lt;int&gt;, costt4_a &lt;int&gt;, ## # grad_debt_mdn &lt;dbl&gt;, avgfacsal &lt;int&gt;, unemp_rate &lt;dbl&gt;, year &lt;chr&gt; "],["clean.html", "Section 3 Data Clean", " Section 3 Data Clean library(tidyverse) Accessibility The data was easily retrievable, the only difficulty was using the API key to retrieve everything into R so we could clean, manipulate, and analyze the data. Appropriate Amount of Data The data had mostly what we were looking for. However, it would have been nice if the data included records of type of school (State vs Liberal Arts vs Ivy League) or average class sizes. This would allow us to look for other correlations or lurking variables between the financial data. Overall, the data was appropriate for our analysis. Believability There is no reason for us to assume the data would be intentionally falsified as it was collected by the U.S. Government to simply compare costs and values of higher education institutions. There have been claims from some colleges (such as Boston University) that there are inaccuracies in the data, however. Concise Representation The data is difficult to navigate through without frequent cross-checking of the documentation. There are many columns that look quite similar but are entirely different measures and statistics. Consistent Representation :The data is presented in the same format consistently throughout the dataset. Ease of Manipulation The data had to be cleaned before any manipulation took place but once that was completed, the data was easy to manipulate. Free-of-Error The data is correct and reliable except for the N/A values that were present before cleaning. Interpretability The data is difficult to interpret without referencing to the documentation continuously. Without the documentation, this dataset would have been very difficult to interpret as a stand-alone. Objectivity The data could be biased as we are looking at institutions which are typically attended to by upper class people. Depending on how the data is interpreted, it could lead to incorrect inferences as there could be many lurking variables unaccounted for. Relevancy The data is well tailored to what we were looking for. Many of the questions we asked were answerable by the data. Reputation The data is well regarded as it has been used for other studies and was introduced by Obama in 2015. It highlighted the Pell grant problem and other financial issues being faced by college students across the country. Security The data is highly secured as it was contained and dispersed by the United States Government. We have no doubts that the security of the data was ever compromised. Timeliness The data is mostly up to date, but it would have been nice to have more recent statistics being recorded as financial data can change quickly as a product of circumstances; like a pandemic. Understandability The data set in-and-of itself was rather complicated, and the documentation did little to assist in approaching the analysis in R. That being said, the data may be more suited for analysts familiar with JSON dem &lt;- read.csv(&quot;Proj1Data/Demographics15to19.csv&quot;) dem_clean &lt;- dem[,-c(1, 17, 20:24)] %&gt;% rename(&quot;university&quot; = instnm, &quot;r_status&quot; = ccbasic, &quot;state&quot; = stabbr, &quot;white&quot; = ugds_white, &quot;black&quot; = ugds_black, &quot;hispanic&quot; = ugds_hisp, &quot;asian&quot; = ugds_asian, &quot;indigenous&quot; = ugds_aian, &quot;nhpi&quot; = ugds_nhpi, &quot;nra&quot; = ugds_nra, &quot;unknown&quot; = ugds_unkn) %&gt;% drop_na(black) dem_clean$r_status &lt;- recode(dem_clean$r_status, `15` = &#39;R1&#39;, `16` = &quot;R2&quot;) dem_clean &lt;- dem_clean %&gt;% group_by(r_status) %&gt;% mutate_at(c(&quot;female&quot;, &quot;first_gen&quot;, &quot;poverty_rate&quot;, &quot;veteran&quot;, &quot;unemp_rate&quot;), funs(ifelse(is.na(.), mean(., na.rm = TRUE),.))) ## Warning: `funs()` is deprecated as of dplyr 0.8.0. ## Please use a list of either functions or lambdas: ## ## # Simple named list: ## list(mean = mean, median = median) ## ## # Auto named with `tibble::lst()`: ## tibble::lst(mean, median) ## ## # Using lambdas ## list(~ mean(., trim = .2), ~ median(., na.rm = TRUE)) ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. write.csv(dem_clean, &quot;Proj1Data/cleanDemographics1519.csv&quot;) fin &lt;- read.csv(&#39;Proj1Data/Financials15to19.csv&#39;) fin_clean &lt;- fin[,-c(2)] %&gt;% rename(&quot;university&quot; = instnm, &quot;r_status&quot; = ccbasic, &quot;state&quot; = stabbr) fin_clean$r_status &lt;- recode(fin_clean$r_status, `15` = &#39;R1&#39;, `16` = &quot;R2&quot;) head(fin_clean) %&gt;% MakePretty() X university r_status state npt4_pub npt4_priv costt4_a grad_debt_mdn avgfacsal unemp_rate year 1 Indiana University-Purdue University-Indianapolis R2 IN 10987 NA 20704 22343 8512 2.90 latest 2 University of Kansas R1 KS 18571 NA 24996 21105 10156 2.50 latest 3 Boston College R1 MA NA 33562 70588 16939 15323 2.88 latest 4 Oakland University R2 MI 11560 NA 21231 25000 9452 3.21 latest 5 University of Mississippi R1 MS 13857 NA 24822 19500 9217 3.64 latest 6 Missouri University of Science and Technology R2 MO 14205 NA 22012 24750 10628 3.05 latest write.csv(fin_clean, &quot;Proj1Data/cleanFinancials1519.csv&quot;) "],["analysis.html", "Section 4 Analysis 4.1 Import 4.2 Transform Datasets 4.3 Descriptive time!", " Section 4 Analysis 4.1 Import library(moments) library(dplyr) library(tidyr) library(stats) library(sjstats) library(ggplot2) fin &lt;- read.csv(&#39;Proj1Data/Financials15to19.csv&#39;) temp &lt;- read.csv(&quot;Proj1Data/Demographics15to19.csv&quot;) death &lt;- read.csv(&quot;Proj1Data/Death15to19.csv&quot;) 4.2 Transform Datasets dem &lt;- temp[,-(20:24)] finR &lt;- fin[fin$ccbasic == c(15,16) &amp; fin$X &lt; 267,] finR1 &lt;- fin[fin$ccbasic == 15 &amp; fin$X &lt; 267,] finR2 &lt;- fin[fin$ccbasic == 16 &amp; fin$X &lt; 267,] demR &lt;- dem[dem$ccbasic == c(15,16) &amp; dem$X &lt; 267,] demR1 &lt;- dem[dem$ccbasic == 15 &amp; dem$X &lt; 267,] demR2 &lt;- dem[dem$ccbasic == 16 &amp; dem$X &lt; 267,] 4.3 Descriptive time! # Demographics summary(demR1$ugds_white) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0573 0.3900 0.5072 0.5129 0.6763 0.8408 skewness(demR1$ugds_white) ## [1] -0.2433317 kurtosis(demR1$ugds_white) ## [1] 2.272319 summary(demR2$ugds_white) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 0.0000 0.4507 0.6242 0.5529 0.7326 0.9348 4 skewness(demR2$ugds_white) ## [1] NA kurtosis(demR2$ugds_white) ## [1] NA # Cost print(&#39;Tuition cost&#39;) ## [1] &quot;Tuition cost&quot; summary(finR1$costt4_a) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 16927 24464 28408 38695 66923 75735 1 hist(finR1$costt4_a) summary(finR2$costt4_a) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 11299 21266 24098 33613 51214 71875 4 hist(finR2$costt4_a) # Students debt print(&#39;Student debt&#39;) ## [1] &quot;Student debt&quot; summary(finR1$grad_debt_mdn) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 8700 17634 20000 19652 22027 27000 hist(finR1$grad_debt_mdn) summary(finR2$grad_debt_mdn) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 5500 20930 23167 22719 25000 30500 5 hist(finR2$grad_debt_mdn) # Unemployment print(&#39;Unemployment Rate&#39;) ## [1] &quot;Unemployment Rate&quot; summary(finR1$unemp_rate) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.190 2.965 3.200 3.293 3.605 5.020 hist(finR1$unemp_rate) summary(finR2$unemp_rate) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 2.320 3.040 3.360 3.545 3.900 7.920 6 hist(finR2$unemp_rate) "],["wilcox-for-skewed-bois.html", "Section 5 Wilcox for skewed bois 5.1 Main model", " Section 5 Wilcox for skewed bois # R1 associated with student outcomes # debt, skewed to all hell so non parametric t-test. wilcox.test(formula=finR$grad_debt_mdn~finR$ccbasic) ## ## Wilcoxon rank sum test with continuity correction ## ## data: finR$grad_debt_mdn by finR$ccbasic ## W = 982, p-value = 1.636e-06 ## alternative hypothesis: true location shift is not equal to 0 # debt for R2 unis significantly differed from R1 students. # non-working t.test(finR$unemp_rate~finR$ccbasic) ## ## Welch Two Sample t-test ## ## data: finR$unemp_rate by finR$ccbasic ## t = -2.6055, df = 118.36, p-value = 0.01035 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.44056117 -0.06007378 ## sample estimates: ## mean in group 15 mean in group 16 ## 3.229683 3.480000 # cost differences between R1, R2. # t.test(finR$costt4_a~finR$ccbasic) # Cant do a t-test cause of the bimodal abomination # Average annual R1 tuition cost: 41,571.97 # Average annual R2 tuition cost: 33,958.16 # white people proportion and unemployment cor(demR$ugds_white, finR$unemp_rate, use = &#39;complete.obs&#39;) ## [1] -0.4912212 # results: White proportion is negatively associated with unemployment (r = -0.49) 5.1 Main model ggplot(finR, aes(unemp_rate, demR$ugds_white,colour=ccbasic)) + geom_point() + geom_smooth(method = &quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 4 rows containing non-finite values (stat_smooth). ## Warning: Removed 4 rows containing missing values (geom_point). # 3 White proportion moderates unemployment outcomes. predictor &lt;- finR$ccbasic moderator &lt;- demR$ugds_white interaction &lt;- predictor * moderator outcome &lt;- finR$unemp_rate wlm &lt;- lm(formula = outcome ~ predictor + moderator + interaction) summary(wlm) ## ## Call: ## lm(formula = outcome ~ predictor + moderator + interaction) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.15537 -0.30223 -0.02668 0.21300 1.58625 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -6.5218 3.7522 -1.738 0.0848 . ## predictor 0.6783 0.2399 2.828 0.0055 ** ## moderator 10.8193 6.4847 1.668 0.0978 . ## interaction -0.7733 0.4140 -1.868 0.0642 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4569 on 120 degrees of freedom ## (4 observations deleted due to missingness) ## Multiple R-squared: 0.3171, Adjusted R-squared: 0.3 ## F-statistic: 18.57 on 3 and 120 DF, p-value: 5.819e-10 5.1.1 Decomposition 5.1.1.1 Simple model predictor &lt;- finR$ccbasic outcome &lt;- finR$unemp_rate simplelm &lt;- lm(formula = outcome ~ predictor) summary(simplelm) ## ## Call: ## lm(formula = outcome ~ predictor) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.03968 -0.34242 -0.08968 0.22008 1.85000 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.52508 1.48566 -0.353 0.7244 ## predictor 0.25032 0.09585 2.612 0.0101 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.5336 on 122 degrees of freedom ## (4 observations deleted due to missingness) ## Multiple R-squared: 0.05294, Adjusted R-squared: 0.04518 ## F-statistic: 6.82 on 1 and 122 DF, p-value: 0.01014 5.1.1.2 Moderator direct effect predictor &lt;- demR$ugds_white outcome &lt;- finR$unemp_rate moderatorlm &lt;- lm(formula = outcome ~ predictor) summary(moderatorlm) ## ## Call: ## lm(formula = outcome ~ predictor) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.35598 -0.35460 -0.04082 0.21356 1.34890 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.0509 0.1200 33.761 &lt; 2e-16 *** ## predictor -1.2801 0.2055 -6.229 6.93e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4776 on 122 degrees of freedom ## (4 observations deleted due to missingness) ## Multiple R-squared: 0.2413, Adjusted R-squared: 0.2351 ## F-statistic: 38.8 on 1 and 122 DF, p-value: 6.927e-09 5.1.1.3 Interaction Effect predictor &lt;- finR$ccbasic moderator &lt;- demR$ugds_white interaction &lt;- predictor * moderator outcome &lt;- finR$unemp_rate interactionlm &lt;- lm(formula = outcome ~ interaction) summary(moderatorlm) ## ## Call: ## lm(formula = outcome ~ predictor) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.35598 -0.35460 -0.04082 0.21356 1.34890 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 4.0509 0.1200 33.761 &lt; 2e-16 *** ## predictor -1.2801 0.2055 -6.229 6.93e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4776 on 122 degrees of freedom ## (4 observations deleted due to missingness) ## Multiple R-squared: 0.2413, Adjusted R-squared: 0.2351 ## F-statistic: 38.8 on 1 and 122 DF, p-value: 6.927e-09 # cost differences between R1, R2. # t.test(finR$costt4_a~finR$ccbasic) # Cant do a t-test cause of the bimodal abomination # Average annual R1 tuition cost: 41,571.97 # Average annual R2 tuition cost: 33,958.16 # white people proportion and unemployment cor(demR$ugds_white, finR$unemp_rate, use = &#39;complete.obs&#39;) ## [1] -0.4912212 # results: White proportion is negatively associated with unemployment (r = -0.49) # 3 White proportion moderates unemployment outcomes. predictor &lt;- finR$ccbasic moderator &lt;- demR$ugds_white interaction &lt;- predictor * moderator outcome &lt;- finR$unemp_rate wlm &lt;- lm(formula = outcome ~ predictor + moderator + interaction) wlm ## ## Call: ## lm(formula = outcome ~ predictor + moderator + interaction) ## ## Coefficients: ## (Intercept) predictor moderator interaction ## -6.5218 0.6783 10.8193 -0.7733 plot(predictor, outcome, type=&quot;n&quot;) abline(-6.5218, 0.67) #abline(y, x, lty=2, col=&quot;red&quot;) #points(predictor[finR$ccbasic==15], outcome[finR$ccbasic==16]) # points(predictor[race==1], outcome[race==1], col=&quot;red&quot;) "],["discussion.html", "Section 6 Discussion", " Section 6 Discussion library(plotly) ## ## Attaching package: &#39;plotly&#39; ## The following object is masked from &#39;package:httr&#39;: ## ## config ## The following object is masked from &#39;package:Hmisc&#39;: ## ## subplot ## The following object is masked from &#39;package:ggplot2&#39;: ## ## last_plot ## The following objects are masked from &#39;package:plyr&#39;: ## ## arrange, mutate, rename, summarise ## The following object is masked from &#39;package:stats&#39;: ## ## filter ## The following object is masked from &#39;package:graphics&#39;: ## ## layout g &lt;- list( scope = &#39;usa&#39;, projection = list(type = &#39;albers usa&#39;), lakecolor = toRGB(&#39;white&#39;) ) avgs &lt;- distinct(FacSalary) plot_geo() %&gt;% add_trace( z = ~avgs$avgSal, span = I(0), colorscale = &#39;matter&#39;, locations = avgs$stabbr, locationmode = &#39;USA-states&#39; ) %&gt;% colorbar(title = NULL) %&gt;% layout(geo = g, title = &quot;Avg. Faculty Salary by State (in USD)&quot;) ## Warning: `arrange_()` is deprecated as of dplyr 0.7.0. ## Please use `arrange()` instead. ## See vignette(&#39;programming&#39;) for more help ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_warnings()` to see where this warning was generated. avgDM &lt;- distinct(debtMedian) plot_geo() %&gt;% add_trace( z = ~avgDM$avgDebt, span = I(0), colorscale = &#39;viridis&#39;, locations = avgDM$state, locationmode = &#39;USA-states&#39; ) %&gt;% colorbar(title = NULL) %&gt;% layout(geo = g, title = &quot;Avg. Faculty Salary by State (in USD)&quot;) library(tidyverse) library(purrr) library(RColorBrewer) library(tmap) cdem &lt;- read.csv(&quot;Proj1Data/cleanDemographics1519.csv&quot;) cdem &lt;- cdem[,-1] dem_pal &lt;- c(&quot;darkolivegreen&quot;, &quot;darkolivegreen3&quot;, &quot;dodgerblue4&quot;, &quot;deepskyblue&quot;, &quot;lavenderblush4&quot;, &quot;lavenderblush2&quot;, &quot;palevioletred1&quot;, &quot;rosybrown1&quot;, &quot;tomato2&quot;, &quot;sienna 1&quot;, &quot;slateblue3&quot;, &quot;thistle1&quot;, &quot;orange&quot;, &quot;navajowhite2&quot;, &quot;lightskyblue3&quot;, &quot;lightsteelblue1&quot;) race_demographics &lt;- cdem %&gt;% select(university, r_status, white, black, hispanic, asian, indigenous, nhpi, nra, unknown) %&gt;% gather(&quot;race&quot;, &quot;percentage&quot;, 3:10, -university) race_demographics %&gt;% ggplot(aes(x = factor(r_status), y = percentage, fill = interaction(r_status, race))) + geom_violin() + stat_summary(fun=mean, geom=&quot;crossbar&quot;, linetype = 1, size=.2, color = &quot;red&quot;) + stat_summary(fun=median, geom=&quot;crossbar&quot;, linetype = 1, size=.2, color = &quot;black&quot;) + labs(title = &quot;Racial Demographics by Carnegie Classification&quot;, subtitle = &quot;Red line = mean | Black line = median\\n&quot;, x = &quot; &quot;, y = &quot;% of Student Body&quot;) + facet_wrap(~as.factor(race), nrow = 5) + scale_fill_manual(values = dem_pal) + theme_gray() + theme(axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), plot.title = element_text(hjust = .5), legend.position = &quot;none&quot;) #Demographics for sparse columns other_demographics &lt;- cdem %&gt;% select(university, r_status, female, first_gen, veteran) %&gt;% gather(&quot;demographic&quot;, &quot;percentage&quot;, 3:5, -university) other_demographics %&gt;% ggplot(aes(x = factor(r_status), y = percentage, fill = interaction(r_status, demographic))) + geom_violin() + stat_summary(fun=mean, geom=&quot;crossbar&quot;, linetype = 2, size=.1, color = &quot;red&quot;) + labs(title = &quot;Other Demographic Factors by Carnegie Classification&quot;, subtitle = &quot;&quot;, x = &quot; &quot;, y = &quot;% of Student Body&quot;) + facet_wrap(~as.factor(demographic), nrow = 5) + scale_fill_brewer(&quot;Paired&quot;) + theme_gray() + theme(axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), plot.title = element_text(hjust = .5), legend.position = &quot;none&quot;) #FUN FACTS #Universities with the highest female/male ratio, the top 10 are mostly R2&#39;s for both categories cdem %&gt;% arrange(desc(female)) %&gt;% filter(female &gt; .50) %&gt;% distinct(university, .keep_all = TRUE) %&gt;% head(10) ## control university r_status state female ## 1 2 Thomas Jefferson University R2 PA 0.7743842 ## 2 1 CUNY Graduate School and University Center R1 NY 0.7729469 ## 3 2 Clark Atlanta University R2 GA 0.7631579 ## 4 2 The New School R2 NY 0.7536302 ## 5 2 Nova Southeastern University R2 FL 0.7459016 ## 6 2 University of New England R2 ME 0.7390681 ## 7 2 Azusa Pacific University R2 CA 0.7258883 ## 8 2 Howard University R2 DC 0.7177579 ## 9 2 Hampton University R2 VA 0.6915352 ## 10 2 Loyola University Chicago R2 IL 0.6876623 ## first_gen poverty_rate veteran unemp_rate white black hispanic asian ## 1 0.3293737 8.770079 0.004961565 3.535827 0.7195 0.0705 0.0136 0.0935 ## 2 0.4395604 14.690000 0.015700483 4.900000 0.2200 0.2893 0.3135 0.1183 ## 3 0.3158522 8.770079 0.004961565 3.535827 0.0004 0.8366 0.0040 0.0018 ## 4 0.1944012 8.770079 0.004961565 3.535827 0.3297 0.0548 0.1195 0.0926 ## 5 0.3733401 8.770079 0.007741348 3.535827 0.3296 0.1617 0.2988 0.0972 ## 6 0.2207308 8.770079 0.004961565 3.535827 0.8274 0.0127 0.0013 0.0354 ## 7 0.3798260 7.950000 0.005801305 3.830000 0.3726 0.0611 0.3322 0.0950 ## 8 0.2363936 10.550000 0.004961565 4.430000 0.0222 0.8863 0.0092 0.0141 ## 9 0.1975117 9.570000 0.004961565 4.010000 0.0142 0.9593 0.0131 0.0014 ## 10 0.2651357 8.770079 0.004545454 3.535827 0.5814 0.0444 0.1425 0.1156 ## indigenous nhpi nra unknown year ## 1 0.0000 0.0000 0.0081 0.0664 2015 ## 2 0.0024 0.0048 0.0228 0.0000 latest ## 3 0.0011 0.0000 0.0241 0.1321 2015 ## 4 0.0011 0.0016 0.3234 0.0400 2016 ## 5 0.0026 0.0009 0.0572 0.0319 2016 ## 6 0.0042 0.0000 0.0034 0.1021 2016 ## 7 0.0029 0.0106 0.0310 0.0233 latest ## 8 0.0013 0.0052 0.0616 0.0000 latest ## 9 0.0025 0.0003 0.0082 0.0008 latest ## 10 0.0006 0.0028 0.0490 0.0139 2015 cdem %&gt;% arrange(female) %&gt;% filter(female &lt; .50) %&gt;% distinct(university, .keep_all = TRUE) %&gt;% head(10) ## control university r_status state ## 1 1 New Jersey Institute of Technology R1 NJ ## 2 1 Missouri University of Science and Technology R2 MO ## 3 1 Colorado School of Mines R2 CO ## 4 1 Michigan Technological University R2 MI ## 5 2 Illinois Institute of Technology R2 IL ## 6 2 Stevens Institute of Technology R2 NJ ## 7 2 Clarkson University R2 NY ## 8 2 Rensselaer Polytechnic Institute R1 NY ## 9 2 Rochester Institute of Technology R2 NY ## 10 2 Worcester Polytechnic Institute R2 MA ## female first_gen poverty_rate veteran unemp_rate white black ## 1 0.1898865 0.3375479 7.624656 0.003439973 3.292901 0.3348 0.0857 ## 2 0.2278168 0.2257366 8.770079 0.004961565 3.535827 0.7815 0.0351 ## 3 0.2631579 0.1719745 8.770079 0.004961565 3.535827 0.7471 0.0104 ## 4 0.2765753 0.1732010 8.770079 0.004961565 3.535827 0.8609 0.0108 ## 5 0.2832370 0.3137255 8.770079 0.004961565 3.535827 0.3257 0.0585 ## 6 0.2847358 0.1549439 5.680000 0.004961565 3.140000 0.6433 0.0219 ## 7 0.2998555 0.1528710 7.160000 0.004961565 3.590000 0.8113 0.0245 ## 8 0.3294118 0.1306505 7.624656 0.003724733 3.292901 0.5907 0.0308 ## 9 0.3355602 0.2022427 8.770079 0.004961565 3.535827 0.6580 0.0495 ## 10 0.3477952 0.1429619 8.770079 0.004961565 3.535827 0.6294 0.0232 ## hispanic asian indigenous nhpi nra unknown year ## 1 0.2210 0.2214 0.0006 0.0006 0.0443 0.0604 2015 ## 2 0.0311 0.0299 0.0037 0.0007 0.0566 0.0348 2015 ## 3 0.0693 0.0488 0.0013 0.0007 0.0589 0.0088 2015 ## 4 0.0185 0.0105 0.0037 0.0005 0.0421 0.0254 2015 ## 5 0.1553 0.1300 0.0034 0.0014 0.2648 0.0428 2015 ## 6 0.1137 0.1459 0.0009 0.0000 0.0351 0.0392 latest ## 7 0.0473 0.0369 0.0030 0.0000 0.0228 0.0188 latest ## 8 0.0813 0.1012 0.0014 0.0002 0.1062 0.0187 2015 ## 9 0.0711 0.0756 0.0018 0.0002 0.0585 0.0542 2015 ## 10 0.0843 0.0457 0.0024 0.0000 0.1226 0.0625 2015 R1s &lt;- cdem %&gt;% filter(r_status == &quot;R1&quot;) ggplot(cdem, aes(x = female)) + geom_histogram(bins = 40, color = &quot;black&quot;, fill = &quot;pink&quot;) + labs(title = &quot;Distribution of Female/Male Gender ratio at R1s&quot;) R2s &lt;- cdem %&gt;% filter(r_status == &quot;R2&quot;) ggplot(R2s, aes(x = female)) + geom_histogram(bins = 40, color = &quot;black&quot;, fill = &quot;skyblue&quot;) + labs(title = &quot;Distribution of Female/Male Gender ratio at R2s&quot;) r1_state &lt;- cdem %&gt;% filter(r_status == &quot;R1&quot;) %&gt;% group_by(state) %&gt;% distinct(university) %&gt;% count() r2_state &lt;- cdem %&gt;% filter(r_status == &quot;R2&quot;) %&gt;% group_by(state) %&gt;% distinct(university) %&gt;% count() g &lt;- list( scope = &#39;usa&#39;, projection = list(type = &#39;albers usa&#39;), lakecolor = toRGB(&#39;white&#39;) ) r1_map &lt;- plot_geo() %&gt;% add_trace( z = ~r1_state$n, span = I(1), colorscale = &#39;Portland&#39;, zauto = F, zmax = 10, zmin = 1, locations = r1_state$state, locationmode = &#39;USA-states&#39; ) %&gt;% colorbar(title = &quot;# of Schools&quot;) %&gt;% layout(geo = g, title = &quot;Number of R1 Schools per State&quot;) r2_map &lt;- plot_geo() %&gt;% add_trace( z = ~r2_state$n, span = I(1), colorscale = &#39;Portland&#39;, zauto = F, zmax = 10, zmin = 1, locations = r2_state$state, locationmode = &#39;USA-states&#39; ) %&gt;% colorbar(title = &quot;# of Schools&quot;) %&gt;% layout(geo = g, title = &quot;Number of R2 Schools per State&quot;) r1_map r2_map "],["references.html", "References", " References "]]
