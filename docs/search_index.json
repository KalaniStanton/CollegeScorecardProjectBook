[["index.html", "An Exploratory Analysis of Data in the U.S. College Scorecard Preface", " An Exploratory Analysis of Data in the U.S. College Scorecard Sara Haman, Adam Lashley, Reilly Stanton, Benjamin Weisman 2020-10-20 Preface This project was completed to satisfy the requirements of a project assigned to students in the Fall 2020 Data Munging and Exploratory Data Analysis at New College of Florida. This document is broken down into sections pertaining to the discrete steps in the process of exploratory data analysis. In the first chapter (1), we present an overview of this project. In the second chapter (2), we outline how we accessed and cleaned the data. We demonstrate our initial attempts at pulling the data directly from the API, and explain why we chose to pivot to using the {rscorecard} package for querying our data from the API. In the third (3), we compute scores on each of the data quality metrics described in Pipino, Lee, and Wang (2002). Although we handle NAs while cleaning the data, the data quality metrics are performed on the initial data pulls, so that our assessment procedure is generally reproducible. The fourth chapter (4) provides the code used to clean the data. Then, we begin the analysis of the data (5). This is done in two steps: first, by exploring the descriptive variables in order to glean the composition of the data set, and second by investigating our theory that the proportion of White students at a school will positively influence student outcomes (possibly due to implicit favor given to White individuals). We examine features that R1 and R2 schools differ on, and provide a model for the relationship between demographics and student outcomes. The results of these tests are reported (5). In this discussion (6), we summarize the key findings from the analysis. "],["intro.html", "Section 1 Introduction", " Section 1 Introduction The Carnegie Classification system classifies American universities by their type and their research productivity. Type is determined by the range of degrees a university awards. Institutions which award at least 20 research-focused doctoral degrees a year are categorized as doctoral universities. Within doctoral universities, schools are given secondary ratings commensurate with the extent of their research expenditures. These ratings, which include R1, R2, and D/PU, are colloquially referenced as a measure of prestige. R1 schools, or schools with very high research activity, are typically represented by old and infamous universities, such as Harvard, and flagship state institutions. However, an R1 designation is not indicative of the quality of research produced, nor the caliber of education one receives at the school. The two factors which influence a schools R status are the ratio of doctoral degrees awarded over faculty count, and the monetary amount the school invests into research. This is to say, an institution could conduct horrible, hackneyed research that never gets published except in predatory journals and still earn an R1 designation if they spend at least 5 million dollars on research expenditures (The Carnegie Classification of Institutes of Higher Education, 2018). Of course, this situation is not realistically feasible. Donors would abandon a school producing blatantly unproductive research. Yet, the reputation of a school is, at some level, intertwined with their R designation. When Dartmouths designation was decremented in 2016, media outlets reported on it as if it were shameful (Anderson, 2016). Without context for how Carnegie Classifications are assigned, the R1 designation may seem superior to R2. Our group chose to investigate the influence of the Carnegie Classification of an institution on student outcomes; essentially, if attending an R1 school provides a tangible benefit over attending an R2. Furthermore, we explore features of R1 and R2 universities to determine which variables they significantly differ on. "],["import.html", "Section 2 Data Acquisition 2.1 Set-up and API Exploration 2.2 The rscorecard and tidyverse approach", " Section 2 Data Acquisition library(plyr) library(tidyverse) library(Hmisc) library(httr) library(jsonlite) library(tidyverse) #install.packages(&quot;tmap&quot;) library(tmap) library(leaflet) library(treemap) library(kableExtra) `%notin%` &lt;- Negate(`%in%`) MakePretty &lt;- function(x) { x %&gt;% kbl(align = &quot;c&quot;) %&gt;% kable_material() } 2.1 Set-up and API Exploration For our project, we wanted to practice using APIs to pull the data into our global environment and extract our desired variables using base R. As you will see, our attempt failed, but was useful in helping us understand the relational structure of the College Scorecard Data and the limits of simple indexing when dealing with complicated data structures. 2.1.1 Project Directory Management Prior to extracting any of the data, we want to ensure that our project is reproducible. Thus, we first create a sub-directory within the users working directory, which will hold the .csv files we will write containing our variables of interest. proj.dir &lt;- getwd() #dir.create(&quot;Proj1Data&quot;) data.dir &lt;- paste0(proj.dir, &quot;/Proj1Data&quot;) Next, we pass the API key into an object so that it can be called in the GET() function, which pulls the data from the API into out global environment. APIKey = &quot;FELgrGb47PaevTWxqZTt6etFaQVnDbKpcJLaPL6a&quot; res = GET(paste0(&quot;https://api.data.gov/ed/collegescorecard/v1/schools?api_key=&quot;, APIKey)) This data is initially in a raw format that is pulled from a JSON file stored on the API servers. To do this, we first convert the raw data to char and call the fromJSON() function to convert the data to a more R friendly data structure. data = fromJSON(rawToChar(res$content)) is(data) ## [1] &quot;list&quot; &quot;vector&quot; Now that this raw JSON file is converted to a list, we can begin our exploration of the data. 2.1.2 API Exploration We originally intended on using list2env(yearsLi, envir = .GlobalEnv) to split the list into multiple data.frame objects, but the fact that the names of the listed data frames are numeric values will be a problem. When calling these data frames, R will have to decide whether the user input 2012 is calling the data$2012 data set, or the number 2012. This is likely to cause problems in our later analysis, so we have to look at the names() of objects in our data list to see how we might adjust our approach to exploring the data. names(data$results) ## [1] &quot;2012&quot; &quot;2011&quot; &quot;2010&quot; &quot;2009&quot; &quot;1998&quot; &quot;2008&quot; ## [7] &quot;1997&quot; &quot;2007&quot; &quot;1996&quot; &quot;2006&quot; &quot;2005&quot; &quot;school&quot; ## [13] &quot;2004&quot; &quot;2003&quot; &quot;2002&quot; &quot;id&quot; &quot;latest&quot; &quot;1999&quot; ## [19] &quot;2001&quot; &quot;2000&quot; &quot;2018&quot; &quot;ope6_id&quot; &quot;2017&quot; &quot;2016&quot; ## [25] &quot;2015&quot; &quot;2014&quot; &quot;2013&quot; &quot;ope8_id&quot; &quot;location&quot; Upon looking at the names() we noticed that not all of the listed data frames are named after years, and thus are likely contain different data than the others. Therefore, we first extract the non-year data frames, prior to extracting the year data frames with a character alteration (to make them non-numeric), id_data &lt;- data$results[c(&quot;school&quot;, &quot;id&quot;, &quot;location&quot;, &quot;ope6_id&quot;, &quot;ope8_id&quot;)] yearsLi&lt;- data$results[names(data$results) %notin% c(&quot;school&quot;, &quot;id&quot;, &quot;location&quot;, &quot;ope6_id&quot;, &quot;ope8_id&quot;)] names(yearsLi) &lt;- paste0(&quot;yr&quot;, names(yearsLi)) #list2env(yearsLi, envir = .GlobalEnv) At this point, we then called list2env(data$results, envir = .GlobalEnv) to create individual dataframes of each object in the yearsLi list, which helped us understand what was happening at different levels of the data structure, but ultimately left us more confused about how we should approach querying this data. This code, as well as the code we used to analyze these objects below, is commented it out because it creates an unnecessary number of objects in the global environment, but retained in this document to show the attempts we made at exploring the data structure. # #names(yr2012) #contents(id_data$school) #contents(yr2012$academics$program$bachelors) #yr2012$academics$program$bachelors #length(id_data$ope8_id) At this point, the challenge of collecting data directly from the API seemed insurmountable, but we sought a solution and turned to the sage of all data science obstacles: Google. 2.2 The rscorecard and tidyverse approach As expected, we found out savior in the annals of algorithmic wisdom when we stumbled upon a package called {rscorecard}. The {rscorecard} package is a wrapper for the College Scorecard API that takes full advantage of the complexity in this relational data structure by employing useful tools from the tidyverse eco-system. Using {dplyr} like functions, specified to this data set, and pipe operators %&gt;% from {magrittr}, the rscorecard package provides an astonishingly simple solution for querying data directly from the API. #install.packages(&quot;rscorecard&quot;) library(rscorecard) To access the API in this package we pass the object holding our API Key [as a string] into the sc_key() function. sc_key(APIKey) As the message above states, once the API key is set, the user can append conditions to the query function sc_get() to extract the data they desire. These conditions are applied using functions in the package, which are appended to the query function using the aforementioned pipes. The primary functions for conditioning the queries are sc_filter(), to collect observations that satisfy boolean expressions, sc_select(), to subset the data by columns, and sc_year(), to select the data from a specified year. These functions are what we use below to extract data on Finances, Demographics, and Death Rates from schools that classify as R1 and R2 research institutions. 2.2.1 Finances F_latest &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(&quot;latest&quot;) %&gt;% sc_get() F_2018 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(2018) %&gt;% sc_get() F_2017 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(2017) %&gt;% sc_get() F_2016 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(2016) %&gt;% sc_get() F_2015 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, npt4_pub, npt4_priv, costt4_a, grad_debt_mdn, avgfacsal, unemp_rate) %&gt;% sc_year(2015) %&gt;% sc_get() F_latest %&gt;% mutate(year = &quot;latest&quot;) F_2018 %&gt;% mutate(year = 2018) F_2017 %&gt;% mutate(year = 2017) F_2016 %&gt;% mutate(year = 2016) F_2015 %&gt;% mutate(year = 2015) Finance &lt;- rbind(F_latest, F_2018, F_2017, F_2016, F_2015) write.csv(Finance, &quot;Proj1Data/Financials15to19.csv&quot;) 2.2.2 Demographics D_latest &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr,female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(&quot;latest&quot;) %&gt;% sc_get() D_2018 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(2018) %&gt;% sc_get() D_2017 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(2017) %&gt;% sc_get() D_2016 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(2016) %&gt;% sc_get() D_2015 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, female, first_gen, poverty_rate, veteran, unemp_rate, ugds_white, ugds_black, ugds_hisp, ugds_asian, ugds_aian, ugds_nhpi, ugds_2mor, ugds_nra, ugds_unkn, ugds_whitenh, ugds_blacknh, ugds_api, ugds_aianold, ugds_hispold) %&gt;% sc_year(2015) %&gt;% sc_get() D_latest %&gt;% mutate(year = &quot;latest&quot;) D_2018 %&gt;% mutate(year = 2018) D_2017 %&gt;% mutate(year = 2017) D_2016 %&gt;% mutate(year = 2016) D_2015 %&gt;% mutate(year = 2015) Demographics &lt;- rbind(D_latest, D_2018, D_2017, D_2016, D_2015) write.csv(Demographics, &quot;Proj1Data/Demographics15to19.csv&quot;) 2.2.3 Death Dth_latest &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(&quot;latest&quot;) %&gt;% sc_get() Dth_2018 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr,death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(2018) %&gt;% sc_get() Dth_2017 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(2017) %&gt;% sc_get() Dth_2016 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(2016) %&gt;% sc_get() Dth_2015 &lt;- sc_init() %&gt;% sc_filter(distanceonly == 0, ccbasic %in% c(15, 16)) %&gt;% sc_select(control, instnm, ccbasic, stabbr, death_yr2_rt, lo_inc_death_yr2_rt, md_inc_death_yr2_rt, hi_inc_death_yr2_rt, death_yr3_rt, lo_inc_death_yr3_rt, md_inc_death_yr3_rt, hi_inc_death_yr3_rt, death_yr4_rt, lo_inc_death_yr4_rt, md_inc_death_yr4_rt, hi_inc_death_yr4_rt, death_yr6_rt, lo_inc_death_yr6_rt, md_inc_death_yr6_rt, hi_inc_death_yr6_rt, death_yr8_rt, lo_inc_death_yr8_rt, md_inc_death_yr8_rt, hi_inc_death_yr8_rt) %&gt;% sc_year(2015) %&gt;% sc_get() Dth_latest %&gt;% mutate(year = &quot;latest&quot;) Dth_2018 %&gt;% mutate(year = 2018) Dth_2017 %&gt;% mutate(year = 2017) Dth_2016 %&gt;% mutate(year = 2016) Dth_2015 %&gt;% mutate(year = 2015) Death &lt;- rbind(Dth_latest, Dth_2018, Dth_2017, Dth_2016, Dth_2015) write.csv(Death, &quot;Proj1Data/Death15to19.csv&quot;) R1Schools &lt;- sc_init() %&gt;% sc_filter(ccbasic == 15) %&gt;% sc_select(control, instnm, stabbr) %&gt;% sc_year(&quot;latest&quot;) %&gt;% sc_get() "],["quality.html", "Section 3 Data Quality 3.1 Set-up 3.2 The Functions 3.3 The Evaluations", " Section 3 Data Quality 3.1 Set-up First, I import the packages that I use in this section and read in the uncleaned data. #LIBRARIES library(tidyverse) library(kableExtra) MakePretty &lt;- function(x) { x %&gt;% kbl(align = &quot;c&quot;) %&gt;% kable_material() } #Reading in the data fin &lt;- read.csv(&#39;Proj1Data/Financials15to19.csv&#39;) fin &lt;- fin[,-1] dem &lt;- read.csv(&quot;Proj1Data/Demographics15to19.csv&quot;) dem &lt;- dem[,-1] 3.2 The Functions CONSISTANT REPRESENTATION con_rep &lt;- function(df){ &quot; A function that quantitatively scores an input data frame on the consistancy of representation data quality metric. Input: df: a data frame Output: con_rep_score: A numeric score on consistency of representation ranging from 1 to 0, where 1 is perfectly consistent representation and 0 is inconsistent representation. &quot; type = vector() for(i in 1:ncol(df)){ col_type &lt;- typeof(df[1,i]) type[i] &lt;- col_type } con_rep_score &lt;- 1 - ((length(unique(type)) - 1)/6) return(con_rep_score) } COMPLETENESS AND EASE OF MANIPULATION data_quality &lt;- function(df){ &quot; A function to quantitatively compute scores for a dataframe on the completeness and ease of manipulation data quality metrics. Input: df: A data frame Output: qualityTable: A table reporting the scores on completeness and ease of manipulation for each column in the input data frame. &quot; # Setting the index value, which will be used to index the column name index &lt;- 1 # Instantiating empty data frames for each of the queries completeness &lt;- data.frame(Completeness=double()) eom &lt;- data.frame(Ease_of_Manipulation=double()) names &lt;- data.frame(ColumnName=character()) # Populating the data frames using a for-loop for (i in df){ # COLLECTING THE NAMES OF EACH COLUMN PASSED col &lt;- colnames(df[index]) # COMPLETENESS # Takes the sum of the total NA, NULL, and NaN values in a column # Divides them by the length of the column # Subtracts this from one, as was suggested by Pipinio, Lee, and Wang # And then rounds to output to the third decimal place c &lt;- 1-(sum(is.na(i) + is.null(i) + is.nan(i))/length(i)) %&gt;% round(digits = 3) # EASE OF MANIPULATION # &quot;Case when&quot; vectorises a series of if/else statements # The function checks the type of the column and then sets the variable, # e, to the corresponding value. e &lt;- case_when( typeof(i) == &quot;logical&quot; ~ 1, typeof(i) == &quot;integer&quot; ~ .9, typeof(i) == &quot;numeric&quot; ~ .8, typeof(i) == &quot;double&quot; ~ .8, typeof(i) == &quot;complex&quot; ~ .7, typeof(i) == &quot;character&quot; ~ .6, typeof(i) == &quot;list&quot; ~ .5, typeof(i) == &quot;raw&quot; ~ 0, TRUE ~ 0) #The index used to collect column names is increased by one index = index + 1 #Appending the output for each column to their respective data frames completeness[nrow(completeness)+1,] &lt;- c eom[nrow(eom)+1,] &lt;- e names[nrow(names)+1,] &lt;- col } #Binding the columns of the three tables into an output table qualityTable &lt;- cbind(names, completeness, eom) return(qualityTable) } 3.3 The Evaluations We assessed data quality using the metrics outlined in (paper). For each of these metrics, we provide a brief commentary on how the data fared. Several of the data quality metrics were more pertinent to our analysis, so we provide deeper insight into them. Accessibility On its own, the data were not accessible and extraction proved to be exceedingly challenging. By using the {rscorecard} package, we were able to streamline the process. However, {rscorecard} is not built into the API and cannot be factored into the datasets baseline accessibility. Despite the challenge of pulling the data into an interpretable form, they can be accessed by the public. This is to say, we did not have to fight with a Facebook executive to access them. We scored the data at a 4/10 for accessibility. Believability There is no reason for us to assume the data would be intentionally falsified as it was collected by the U.S. Government to simply compare costs and values of higher education institutions. There have been claims from some colleges (such as Boston University) that there are inaccuracies in the data, however. We decided to give the data a score of 8/10 on believability. Concise Representation The data is difficult to navigate through without frequent cross-checking of the documentation. There are many columns that look quite similar but are entirely different measures and statistics. For example, within the demographics data there are multiple ways the racial makeup of a university are encoded. These columns appear to contain the same information drawn from perhaps different sources. However, the data is not consistent between sources and, at least within the demographics variables, contained large swaths of NAs. Based on our subjective experience with the data, we assigned it a score of 4/10 because it could, theoretically, be worse. Consistent Representation We calculated consistent representation by creating a function that collected the type for each row of a data frame. The function counts the number of unique types that occur in the data frame minus one (for scoring purposes). This number is then divided by the total number of types possible minus one. This number is subtracted from 1. If all of the data are encoded the same way, they will receive a score of 1. This is because the function will read that there is one unique type in the data frame. One will be subtracted from this, leading the function to divide 0/6, resulting in 0. 1 - 0 is 1. 1 was set as the highest score so that it would correspond with the other measures of data quality. If the data uses all 7 different kinds of data type that can be reasonably encoded, it will receive a score of 0. The Financials data set had three unique types, and received a score of .667. The Demographics data set had four unique data types, and received a score of 0.5. #CONSISTENCY OF REPRESENTATION FOR THE FINANCIALS DATA paste(&quot;Score:&quot;, round(con_rep(fin),3)) ## [1] &quot;Score: 0.667&quot; #CONSISTENCY OF REPRESENTATION FOR THE DEMOGRAPHICS DATA paste(&quot;Score:&quot;, round(con_rep(dem),3)) ## [1] &quot;Score: 0.5&quot; Completeness Completeness was measured by summing the total number of blank data rows in each column - blank referring to rows containing either NA, NaN, or Null - and dividing this by the total number of rows. A score of 1 indicates perfect completeness. A score of 0 indicates no completeness, or a column of entirely null data. Within the Financial dataset, scores on completeness varied from 1, for the key values, to .195 for the unemployment rate. The mean completeness score over the entire dataset was 0.812, which indicates a moderate level of completeness. The Demographic dataset had a wider range of scores. Like the Financial dataset, the key values were awarded a completeness score of 1. However, response rates for the demographic variables had a wide distribution. The major races, such as White, Black, Hispanic, Asian, etc. had response rates of .983. However, response rates for ethnicities, such as White (non-hispanic) and Black (non-hispanic) had a response rate of 0. These variables were dropped during the cleaning process; however, they still skewed the mean completeness score for this variable. The mean completeness for the Demographic dataset was 0.658. Ease of Manipulation Ease of manipulation was quantified using the rules of coercion in R (as outlined in OReilly, R in a Nutshell, 2nd Edition). Since certain base R operations can only be performed on specific data types, the data type integrally influences how easily the data can be used and manipulated. The easier a data type is to coerce, or manipulate, into another data type, the higher a score it obtains. The gradient of scores moves from the logical (i.e., TRUE/FALSE) data type, which can be easily coerced into every other data types, to the raw data type, which cannot be implicitly coerced into other data types and is difficult to explicitly coerce. Because the logical data type can be universally manipulated, it scores a one. Since the raw data type cannot be coerced into another data type, it obtains an ease of manipulation score of zero. Rare data types, such as time series, were not included in the base version of this function because they are rarely included in data frames. Matrices were not included because it is nearly impossible to work them into a data frame, and because typeof returns their type as the type of data that is included within them. The ease of manipulation scores for both data sets are included below. The average ease of manipulation score for the Financials data set was 0.8, which indicates good ease of manipulation. The average ease of manipulation score for the Demographics data set was 0.825, which also indicates good ease of manipulation. FINANCIALS METRICS Completeness Ease_of_Manipulation control 1.000 0.9 instnm 1.000 0.6 ccbasic 1.000 0.9 stabbr 1.000 0.6 npt4_pub 0.688 0.9 npt4_priv 0.287 0.9 costt4_a 0.977 0.9 grad_debt_mdn 0.785 0.8 avgfacsal 0.996 0.9 unemp_rate 0.195 0.8 year 1.000 0.6 ## [1] &quot;Mean over columns: 0.8&quot; DEMOGRAPHICS METRICS Completeness Ease_of_Manipulation control 1.000 0.9 instnm 1.000 0.6 ccbasic 1.000 0.9 stabbr 1.000 0.6 female 0.591 0.8 first_gen 0.586 0.8 poverty_rate 0.195 0.8 veteran 0.382 0.8 unemp_rate 0.195 0.8 ugds_white 0.983 0.8 ugds_black 0.983 0.8 ugds_hisp 0.983 0.8 ugds_asian 0.983 0.8 ugds_aian 0.983 0.8 ugds_nhpi 0.983 0.8 ugds_2mor 0.983 0.8 ugds_nra 0.983 0.8 ugds_unkn 0.983 0.8 ugds_whitenh 0.000 1.0 ugds_blacknh 0.000 1.0 ugds_api 0.000 1.0 ugds_aianold 0.000 1.0 ugds_hispold 0.000 1.0 year 1.000 0.6 ## [1] &quot;Mean over columns: 0.825&quot; Reputation The data is well regarded as it has been used for other studies and was introduced by Obama in 2015. It highlighted the Pell grant problem and other financial issues being faced by college students across the country. Based on our subjective experience with the data, we assigned it a score of 8/10. It was not assigned a 10/10 because of some disputes about the quality of the data which have been raised by universities included in it. Security The data is highly secured as it was contained and dispersed by the United States Government. It is publicly accessible - however, this should not compromise the security of the data. There have been no known hackings of the data. We decided to assign the data a security score of 10/10. Timeliness The data is mostly up to date, but it would have been nice to have more recent statistics being recorded as financial data can change quickly as a product of circumstances; like a pandemic. Based on our subjective experience with the data, we assigned it a score of 9/10. "],["clean.html", "Section 4 Data Cleaning 4.1 Demographics 4.2 Financials", " Section 4 Data Cleaning After the initial parsing of the data in the acquisition phase, there was not a significant amount of cleaning to be done. The cleaning stage primarily consisted of organizing the variables in a way that was intuitive to work with. We chose to handle NAs by replacing them with the group mean determined by their Carnegie classification. For the demographics data set, we first dropped extraneous columns. These were columns which consisted of more than 90% NA values. Then, we renamed the variables so that they would be more intuitive to a general audience (and so that we could remember them better). There were four schools within the data that did not report any demographic variables for every year that they were in the data set. These schools were removed using drop_na(black), because the black column did not possess any NAs other than for these four schools. For both data sets, we chose to recode the Carnegie Classification variable (called r_status) as R1 and R2 to increase the interpretability of the data. These are converted to factors in the analysis section so that they can be input into the models. 4.1 Demographics #IMPORTING PACKAGES library(tidyverse) # READING IN THE CSV dem &lt;- read.csv(&quot;Proj1Data/Demographics15to19.csv&quot;) # CLEANING THE DATA FRAME dem_clean &lt;- dem[,-c(1, 17, 20:24)] %&gt;% rename(&quot;university&quot; = instnm, &quot;r_status&quot; = ccbasic, &quot;state&quot; = stabbr, &quot;white&quot; = ugds_white, &quot;black&quot; = ugds_black, &quot;hispanic&quot; = ugds_hisp, &quot;asian&quot; = ugds_asian, &quot;indigenous&quot; = ugds_aian, &quot;nhpi&quot; = ugds_nhpi, &quot;nra&quot; = ugds_nra, &quot;unknown&quot; = ugds_unkn) %&gt;% drop_na(black) # RECODING THE CARNEGIE CLASSIFICATION (R_STATUS) VARIABLE dem_clean$r_status &lt;- recode(dem_clean$r_status, `15` = &#39;R1&#39;, `16` = &quot;R2&quot;) # NA HANDLING dem_clean &lt;- dem_clean %&gt;% group_by(r_status) %&gt;% mutate_at(c(&quot;female&quot;, &quot;first_gen&quot;, &quot;poverty_rate&quot;, &quot;veteran&quot;, &quot;unemp_rate&quot;), funs(ifelse(is.na(.), mean(., na.rm = TRUE),.))) # WRITING TO A NEW CSV write.csv(dem_clean, &quot;Proj1Data/cleanDemographics1519.csv&quot;) 4.2 Financials The Financials data set was easier to work with; as such, we simply renamed the common variables that we had renamed with demographics and re-coded the Carnegie Classification. # READING IN THE CSV fin &lt;- read.csv(&#39;Proj1Data/Financials15to19.csv&#39;) # RENAMING VARIABLES SO THAT THEY MATCH THE DEMOGRAPHIC DATA FRAME fin_clean &lt;- fin[,-c(2)] %&gt;% rename(&quot;university&quot; = instnm, &quot;r_status&quot; = ccbasic, &quot;state&quot; = stabbr) # RECODING THE CARNEGIE CLASSIFICATION (R_STATUS) VARIABLE fin_clean$r_status &lt;- recode(fin_clean$r_status, `15` = &#39;R1&#39;, `16` = &quot;R2&quot;) # WRITING TO A NEW CSV write.csv(fin_clean, &quot;Proj1Data/cleanFinancials1519.csv&quot;) #DISPLAYING THE NEW CSV head(dem_clean, 5) ## # A tibble: 5 x 18 ## # Groups: r_status [2] ## control university r_status state female first_gen poverty_rate veteran ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 Indiana U~ R2 IN 0.610 0.351 6.20 0.00394 ## 2 1 Universit~ R1 KS 0.548 0.222 5.24 0.00429 ## 3 2 Boston Co~ R1 MA 0.519 0.132 5.93 0.00372 ## 4 1 Oakland U~ R2 MI 0.608 0.324 5.74 0.00231 ## 5 1 Universit~ R1 MS 0.608 0.235 12.2 0.00176 ## # ... with 10 more variables: unemp_rate &lt;dbl&gt;, white &lt;dbl&gt;, black &lt;dbl&gt;, ## # hispanic &lt;dbl&gt;, asian &lt;dbl&gt;, indigenous &lt;dbl&gt;, nhpi &lt;dbl&gt;, nra &lt;dbl&gt;, ## # unknown &lt;dbl&gt;, year &lt;chr&gt; "],["analysis.html", "Section 5 Methods and Results 5.1 Methods 5.2 Results", " Section 5 Methods and Results library(papeR) library(kableExtra) 5.1 Methods Sample. The sample for this study consisted of universities in the United States of America. In this way, we were able to examine what was nearly the population of college students in America. However, the high frequency of NA variables in some categories hindered Procedure. The data was collected by accessing the public College Scorecard API. The procedure for extracting and cleaning the data is explained in the Data Extraction and Data Clean sections. Analysis Strategy. We quantified student outcomes using the median debt and unemployment rate variables. These variables were selected because they are tangibly related to financial outcomes. Other potential measures of success in the data, such as completion rates and death rates, contained either very sparse data or were ambiguous. For instance, neither transferring nor withdrawing from a University are necessarily indicative of a poor outcome (insofar as it relates to student success after attending the University). Both debt and unemployment, however, are. High rates of debt implicate a school with insufficient financial aid programs. High debt medians also potentially imply students are not placed into high-paying jobs that would allow them to expediently repay their debt. High rates of unemployment suggest that students have trouble finding jobs after graduation. As the goal of a university education is largely to educate a student to assist with their career, students being unable to find jobs is a poor outcome. The demographic variables were selected by inspecting all the demographic variables in the dataset and selecting the ones that were mostly complete. We decided to look at the demographic makeup of R1 and R2 universities to determine if there was a significant difference between the student body profiles. Race and gender are often discussed in relation to student success, due to a history of systematic discrimination within the American university system. These were our primary variables of interest. Specifically, we were interested in the ratio of White students to minority students. However, we briefly examined veteran and first generation status. 5.2 Results SET-UP # IMPORTING PACKAGES library(moments) library(dplyr) library(tidyr) library(stats) library(sjstats) library(ggplot2) library(plotly) library(tidyverse) library(purrr) library(RColorBrewer) library(tmap) # READING IN THE CSVs fin &lt;- read.csv(&#39;Proj1Data/cleanFinancials1519.csv&#39;) cdem &lt;- read.csv(&#39;Proj1Data/cleanDemographics1519.csv&#39;) fin$r_status &lt;- factor(fin$r_status, levels = c(&quot;R1&quot;, &quot;R2&quot;), labels = c(1,2)) cdem$r_status &lt;- factor(cdem$r_status, levels = c(&quot;R1&quot;, &quot;R2&quot;), labels = c(1,2)) # TRANSFORMING THE DATASETS finR &lt;- fin[fin$year == &quot;latest&quot;,] finR1 &lt;- fin[fin$r_status == 1 &amp; fin$year == &quot;latest&quot;,] finR2 &lt;- fin[fin$r_status == 2 &amp; fin$year == &quot;latest&quot;,] demR &lt;- cdem[cdem$year == &quot;latest&quot;,] demR1 &lt;- cdem[cdem$r_status == 1 &amp; cdem$year == &quot;latest&quot;,] demR2 &lt;- cdem[cdem$r_status == 2 &amp; cdem$year == &quot;latest&quot;,] finR &lt;- subset(finR, university %in% demR$university) 5.2.1 Demographic Descriptive Statistics LOCATION OF R1S vs. R2S Before analyzing the demographic differences, we thought it was important to display how R1 and R2 schools are distributed across the United States. The demographic makeup of a school is potentially influenced by the demographics of in-state students which, at least at public institutions, are proportionally more likely to attend the school than students from any other state (see State Council of Higher Education for Virginia, 2019 for a case study of one state). Although we do not factor state and baseline state demographics into our model, it is a potential influential third variable that should be kept in mind while interpretting race and income demographics. r1_state &lt;- cdem %&gt;% filter(r_status == &quot;1&quot;) %&gt;% group_by(state) %&gt;% distinct(university) %&gt;% count() r2_state &lt;- cdem %&gt;% filter(r_status == &quot;2&quot;) %&gt;% group_by(state) %&gt;% distinct(university) %&gt;% count() g &lt;- list( scope = &#39;usa&#39;, projection = list(type = &#39;albers usa&#39;), lakecolor = toRGB(&#39;white&#39;) ) r1_map &lt;- plot_geo() %&gt;% add_trace( z = ~r1_state$n, span = I(1), colorscale = &#39;Portland&#39;, zauto = F, zmax = 10, zmin = 1, locations = r1_state$state, locationmode = &#39;USA-states&#39; ) %&gt;% colorbar(title = &quot;# of Schools&quot;) %&gt;% layout(geo = g, title = &quot;Number of R1 Schools per State&quot;) r2_map &lt;- plot_geo() %&gt;% add_trace( z = ~r2_state$n, span = I(1), colorscale = &#39;Portland&#39;, zauto = F, zmax = 10, zmin = 1, locations = r2_state$state, locationmode = &#39;USA-states&#39; ) %&gt;% colorbar(title = &quot;# of Schools&quot;) %&gt;% layout(geo = g, title = &quot;Number of R2 Schools per State&quot;) r1_map r2_map RACE The prelimary examination of the demographics data revealed that all of the race values, except for the proportion of white students, had a significant right skew. While the distributions are not normal, they are symmetric and bounded, which prevents extreme outliers. Below we provide a violin plot showing the distribution for each of the race variables grouped by their Carnegie classification. The mean is marked by a red bar, and the median is marked by a black bar. dem_pal &lt;- c(&quot;darkolivegreen&quot;, &quot;darkolivegreen3&quot;, &quot;dodgerblue4&quot;, &quot;deepskyblue&quot;, &quot;lavenderblush4&quot;, &quot;lavenderblush2&quot;, &quot;palevioletred1&quot;, &quot;rosybrown1&quot;, &quot;tomato2&quot;, &quot;sienna 1&quot;, &quot;slateblue3&quot;, &quot;thistle1&quot;, &quot;orange&quot;, &quot;navajowhite2&quot;, &quot;lightskyblue3&quot;, &quot;lightsteelblue1&quot;) race_demographics &lt;- cdem %&gt;% select(university, r_status, white, black, hispanic, asian, indigenous, nhpi, nra, unknown) %&gt;% gather(&quot;race&quot;, &quot;percentage&quot;, 3:10, -university) race_demographics %&gt;% ggplot(aes(x = factor(r_status), y = percentage, fill = interaction(r_status, race))) + geom_violin() + stat_summary(fun=mean, geom=&quot;crossbar&quot;, linetype = 1, size=.2, color = &quot;red&quot;) + stat_summary(fun=median, geom=&quot;crossbar&quot;, linetype = 1, size=.2, color = &quot;black&quot;) + labs(title = &quot;Racial Demographics by Carnegie Classification&quot;, subtitle = &quot;Red line = mean | Black line = median\\n&quot;, x = &quot; &quot;, y = &quot;% of Student Body&quot;) + facet_wrap(~as.factor(race), nrow = 5) + scale_fill_manual(values = dem_pal) + theme_gray() + theme(axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), plot.title = element_text(hjust = .5), legend.position = &quot;none&quot;) The five number summary for the white variable, along with the skewness and kurtosis, are reported below. # DEMOGRAPHICS AT R1&#39;S - WHITE STUDENTS summary(demR1$white) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0573 0.3900 0.5072 0.5129 0.6763 0.8408 skewness(demR1$white) ## [1] -0.2433317 kurtosis(demR1$white) ## [1] 2.272319 # DEMOGRAPHICS AT R2&#39;S - WHITE STUDENTS summary(demR2$white) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 0.0000 0.4507 0.6242 0.5529 0.7326 0.9348 skewness(demR2$white) ## [1] -0.9043165 kurtosis(demR2$white) ## [1] 2.917131 OTHER DEMOGRAPHICS The non-racial variables (i.e., gender, first generation status, veteran status) did not posess the same skew. However, the mean was inflated due to how we coded NAs resulting in peculiar looking violin plots. #Demographics for sparse columns other_demographics &lt;- cdem %&gt;% select(university, r_status, female, first_gen, veteran) %&gt;% gather(&quot;demographic&quot;, &quot;percentage&quot;, 3:5, -university) other_plot &lt;- other_demographics %&gt;% ggplot(aes(x = factor(r_status), y = percentage, fill = interaction(r_status, demographic))) + geom_violin() + stat_summary(fun=mean, geom=&quot;crossbar&quot;, linetype = 2, size=.1, color = &quot;red&quot;) + labs(title = &quot;Other Demographic Factors by Carnegie Classification&quot;, subtitle = &quot;&quot;, x = &quot; &quot;, y = &quot;% of Student Body&quot;) + facet_wrap(~as.factor(demographic), nrow = 5) + scale_fill_brewer(&quot;Paired&quot;) + theme_gray() + theme(axis.title.y = element_text(margin = margin(t = 0, r = 20, b = 0, l = 0)), plot.title = element_text(hjust = .5), legend.position = &quot;none&quot;) other_plot 5.2.2 Financial Descriptive Statistics The code for the first histogram is displayed, the rest will be hidden to avoid unnecessary repitition. # Cost print(&#39;Tuition cost&#39;) ## [1] &quot;Tuition cost&quot; summary(finR1$costt4_a) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 16927 24464 28408 38695 66923 75735 1 cost_hist1 &lt;- ggplot(finR1, aes(x =costt4_a)) + geom_histogram(bins = 40, color = &quot;black&quot;, fill = &quot;red&quot;) + labs(title = &quot;Distribution of Tuition Costs at R1s&quot;, subtitle = &quot;&quot;, x = &quot;Cost (in American dollars)&quot;, y = &quot;Frequency&quot;) cost_hist1 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 11299 21266 24098 33613 51214 71875 4 ## [1] &quot;Student debt&quot; ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 8700 17634 20000 19652 22027 27000 ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 5500 20930 23167 22719 25000 30500 5 Unemployment print(&#39;Unemployment Rate&#39;) ## [1] &quot;Unemployment Rate&quot; summary(finR1$unemp_rate) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 2.190 2.965 3.200 3.293 3.605 5.020 unemp_hist1 &lt;- ggplot(finR1, aes(x = unemp_rate)) + geom_histogram(bins = 40, color = &quot;black&quot;, fill = &quot;darkseagreen4&quot;) + labs(title = &quot;Distribution of Post-Graduation Unemployment rates at R1s&quot;, subtitle = &quot;&quot;, x = &quot;Unemployment Rate&quot;, y = &quot;Frequency&quot;) unemp_hist1 summary(finR2$unemp_rate) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 2.320 3.040 3.360 3.545 3.900 7.920 6 unemp_hist2 &lt;- ggplot(finR2, aes(x = unemp_rate)) + geom_histogram(bins = 40, color = &quot;black&quot;, fill = &quot;darkseagreen3&quot;) + labs(title = &quot;Distribution of Post-Graduation Unemployment rates at R2s&quot;, subtitle = &quot;&quot;, x = &quot;Unemployment Rate&quot;, y = &quot;Frequency&quot;) unemp_hist2 5.2.3 Significance Testing Preliminary normality analysis of the median graduate debt distribution revealed levels of skewness that forbade the use of parametric comparison tests. A Wilcoxon signed-rank test was conducted in order to investigate the differences in median graduate debt between R1 and R2 institutions. Results indicate that median graduate debt significantly differed between R1 and R2 institutions (W = 982, p &lt; 0.01). While a difference in student debt was expected due to the aforementioned price of R1 institution tuition, descriptive statistics revealed graduates of R1 institutions graduated with less average debt (M = 19,652, SD = 3,750) than students from R2 institutions (M = 22,719, SD = 3,785). wilcox.test(formula=finR$grad_debt_mdn~finR$r_status) ## ## Wilcoxon rank sum test with continuity correction ## ## data: finR$grad_debt_mdn by finR$r_status ## W = 4430.5, p-value = 2.092e-11 ## alternative hypothesis: true location shift is not equal to 0 In order to further explore student outcomes, the investigators turned their attention to the graduate unemployment rate. The distribution for unemployment exhibited skewness and kurtosis values within acceptable bounds so a Welchs two-sample t-test was conducted in order to find whether there were significant differences in unemployment rates between R1 and R2 graduates. The test revealed significant differences in rates of unemployment between R1 and R2 graduates t(118.36) = -2.6055, p = 0.01, 95%C.I. [-0.44, -0.06]. On average, the unemployment rate for R1 graduates (M = 3.293, SD = 0.51) was lower than that observed for R2 graduates (M = 3.545, SD = 0.83) t.test(finR$unemp_rate~finR$r_status) ## ## Welch Two Sample t-test ## ## data: finR$unemp_rate by finR$r_status ## t = -2.7918, df = 208.77, p-value = 0.005728 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.41446370 -0.07138832 ## sample estimates: ## mean in group 1 mean in group 2 ## 3.292901 3.535827 5.2.4 Regression model The racial diversity proportion of an institution was examined as a potential moderator of the relationship between institution type (R1 vs. R2) and unemployment rate. In the first step of the regression analysis institution type was entered into the model and accounted for 5% of the variance in unemployment rate, which was significant, R2= 0.52, F(1,122) = 6.82, p = 0.01. In the second step of the regression analysis the interaction effect between institution type and racial diversity proportion were entered into the model and explained an additional 4% of the variance in unemployment rate, which was significant, R2= 0.04, F(1,121) = 8.57, p &lt; 0.05. Racial diversity proportion was entered into the model last and accounted for 24% of the variance in unemployment rate, which was significant, R2= 0.24, F(1,122) = 38.8 , p &lt; 0.01. Thus, racial diversity proportion was a significant moderator of the relationship between institution type and unemployment rate. Note: Below the code for each model is a statistical summary of the model made using the {papeR} package for data formatting and {kableExtra} for clean presentation. This code is hidden for cleanliness of the document pretty_lm &lt;- prettify(summary(lm)) #prettify() from papeR kable(pretty_lm) #kable() from kableExtra Model step 1 predictor &lt;- finR$r_status outcome &lt;- finR$unemp_rate simplelm &lt;- lm(formula = outcome ~ predictor) Estimate CI (lower) CI (upper) Std. Error t value Pr(&gt;|t|) (Intercept) 3.292901 3.1735133 3.4122882 0.0606251 54.31578 &lt;0.001 *** predictor: 2 0.242926 0.0727624 0.4130896 0.0864093 2.81134 0.005 ** Model step 2 predictor &lt;- demR$white outcome &lt;- finR$unemp_rate moderatorlm &lt;- lm(formula = outcome ~ predictor) Estimate CI (lower) CI (upper) Std. Error t value Pr(&gt;|t|) (Intercept) 4.349973 4.154740 4.545205 0.0991392 43.87741 &lt;0.001 *** predictor -1.752903 -2.091579 -1.414227 0.1719802 -10.19247 &lt;0.001 *** Model step 3 predictor &lt;- as.integer(finR$r_status) moderator &lt;- demR$white interaction &lt;- predictor * moderator outcome &lt;- finR$unemp_rate interactionlm &lt;- lm(formula = outcome ~ interaction) Estimate CI (lower) CI (upper) Std. Error t value Pr(&gt;|t|) (Intercept) 3.8097381 3.6479823 3.9714939 0.0821398 46.381133 &lt;0.001 *** interaction -0.4909286 -0.6635793 -0.3182778 0.0876723 -5.599587 &lt;0.001 *** Complete model predictor &lt;- as.integer(finR$r_status) moderator &lt;- demR$white interaction &lt;- predictor * moderator outcome &lt;- finR$unemp_rate wlm &lt;- lm(formula = outcome ~ predictor + moderator + interaction) Estimate CI (lower) CI (upper) Std. Error t value Pr(&gt;|t|) (Intercept) 3.1621503 2.5291324 3.7951683 0.3214354 9.8375933 &lt;0.001 *** predictor 0.7868949 0.4041791 1.1696107 0.1943364 4.0491387 &lt;0.001 *** moderator -0.4052437 -1.5502012 0.7397137 0.5813892 -0.6970265 0.486 interaction -0.8739274 -1.5470257 -0.2008290 0.3417875 -2.5569321 0.011 "],["discussion.html", "Section 6 Discussion 6.1 Discussion 6.2 The Project Process 6.3 Things Learned &amp; Skills Acquired 6.4 Other fun things", " Section 6 Discussion 6.1 Discussion These results are meant to serve as illustration of the data in the College Scorecard API pertaining to schools at the highest levels of Carnegie Classification. In addition to the descriptive analysis, which demonstrates the distributions of demographics and financial data, our regression analysis demonstrates that the distinction between R1 or R2 classifications has a significant, albeit small effect on unemployment rates for graduates from these universities. Interestingly, the relationship between unemployment and School type was moderated by the proportion of white people at a given university. Commentary on the social conditions surrounding this relationship is beyond the scope of this project and the researchers expertise; nevertheless, we hope these results serve others in discussions of systemic issues related to race and higher education. 6.2 The Project Process We should admit that at the onset of this project our team was lost in the complexity of the data in the College Scorecard API. This was largely due to our own stubbornness, as we wanted to use the API because of the advantages this method offers in regards to reproducibility. That being said, our project scope began to grow exponentially after learning about the rscorecard package, which not only offered a highly interpretable method for extracting the data but also offered further insight into how the data from the API was structured in and of itself. Prior to developing a plan for our analysis (or even a direction for the project) we began by setting up the repositories and collaborative documents that we planned to use throughout the project. The primary collaborative tools were GitHub, Google Docs, and Discord. We used Discord to keep in contact because of their native support for markdown as part of their messaging service, which allowed us to send code chunks directly to each other, as well as the voice-conferencing and screen sharing functionality that allowed us to meet and discuss progress. The Google Docs were primarily used for planning and drafting the written portions of our project. Lastly, we used github to share files with one another and used the gitpages feature to host the final document as a web page. The documents in the CollegeScorecardProjectBook repository contain all of the code, data, and configuration files needed in order to knit the bookdown on each team members computer. Ultimately, this means that a cloned repository of our GitHub should run and knit, just as long as the user acquires their own API key and installs all the necessary dependencies into their RStudio environment. In truth, this project suffered from quite a bit of feature creep once we began working on the project in earnest. As we finally began to understand the data, we realized there were a lot of ways that we could take full advantage of the information at our disposal using the specialized skill sets of our team members. Consequently, we were unable to discuss all of the visualizations that we had made during this process, but have included them in case anyone would like to use our code as reference for their own exploratory projects in the future. 6.3 Things Learned &amp; Skills Acquired 6.3.1 Adam I was incredibly surprised by how much we were able to glean from only a handful of variables of interest. We definitely came into the exploratory analysis laptops blazing to burn down the ivory R1 throne but alas the dataset managed to both defuse our animosity and reveal a much more realistic painting of R1 characteristics. I feel that we were able to learn alot about the diversity characteristics and outcomes of R1 vs R2 schools in spite of the projects fairly narrow scope. On a different note, I really enjoyed getting to work with holistically skewed and messy data. On a longer time scale I would have loved to seek out and model some of the more obscure latent variables and their relation to student outcomes. people use statistics the same way that a drunk uses a lamppost. More for support than for illumination. Andrew Lang, a long ass time ago 6.3.2 Kalani Despite my previous endeavors with Bookdown (I had knit one years ago), I struggled to navigate the highly technical documentation available for this package. Nevertheless, I persisted and was able to create a clean document format that parallelled the fantastic work put in by my other team members. Through Adams work on statistical analysis, I became re-acquainted with some of the modeling and statistical tools I had used in my undergrad data science and psychology classes, but had also learned more about experimental design from Adam himself. I also collaborated with Sara to make the interactive chloropleth maps using plotly, which I had never done before and am happy I took the time to learn. All in all, Im really pleased with this project and appreciated the diverse skill set across the members of this team. There is no such thing as a good programmer; just a competent googler. ~Unknown 6.3.3 Sara Most of what I learned from this project I learned from my partners. Kalanis Bookdown and data-wrangling ingenuity and Adams statistics proficiency added layers to the learning experience, and made the assignment fun to work on. I also enjoyed reading Bens interpretation of the subjective data quality features. I was impressed by how much we were able to do with a fairly sparse and limited data set. We managed to probe at a topic I find genuinely interesting, and scrape insights from below the surface level of the data. I also enjoyed being able to implement the data quality functions I created for the homework assignment on actual data sets. It provided meaning to the work we had completed so far. 6.3.4 Ben This group project gave us all some much-needed group work experience as well as sharpened our technical skills in R and Git. We collaborated using a Git Repository and Kalani used Bookdown for the formal writeup. It was an interesting experience, and we all were able to contribute in our own way. As for what we learned, the dataset showed us real data about the distribution and diversity of colleges across the United States. When we usually think about these institutions, we come in with our own pre -conceived biases and opinions but when we look at the actual data, we can begin to formulate real inferences and conclusions. In our other works, we havent had this experience yet, so it was a nice change of pace. 6.4 Other fun things Features that we were interested in, but didnt get a chance to follow through on or did not align with the primary goal of the project. :) 6.4.1 Gender #Universities with the highest female/male ratio, the top 10 are mostly R2&#39;s for both categories cdem %&gt;% arrange(desc(female)) %&gt;% filter(female &gt; .50) %&gt;% distinct(university, .keep_all = TRUE) %&gt;% head(10) %&gt;% MakePretty() X control university r_status state female first_gen poverty_rate veteran unemp_rate white black hispanic asian indigenous nhpi nra unknown year 1244 2 Thomas Jefferson University 2 PA 0.7743842 0.3293737 8.770079 0.0049616 3.535827 0.7195 0.0705 0.0136 0.0935 0.0000 0.0000 0.0081 0.0664 2015 196 1 CUNY Graduate School and University Center 1 NY 0.7729469 0.4395604 14.690000 0.0157005 4.900000 0.2200 0.2893 0.3135 0.1183 0.0024 0.0048 0.0228 0.0000 latest 1077 2 Clark Atlanta University 2 GA 0.7631579 0.3158522 8.770079 0.0049616 3.535827 0.0004 0.8366 0.0040 0.0018 0.0011 0.0000 0.0241 0.1321 2015 844 2 The New School 2 NY 0.7536302 0.1944012 8.770079 0.0049616 3.535827 0.3297 0.0548 0.1195 0.0926 0.0011 0.0016 0.3234 0.0400 2016 880 2 Nova Southeastern University 2 FL 0.7459016 0.3733401 8.770079 0.0077413 3.535827 0.3296 0.1617 0.2988 0.0972 0.0026 0.0009 0.0572 0.0319 2016 839 2 University of New England 2 ME 0.7390681 0.2207308 8.770079 0.0049616 3.535827 0.8274 0.0127 0.0013 0.0354 0.0042 0.0000 0.0034 0.1021 2016 85 2 Azusa Pacific University 2 CA 0.7258883 0.3798260 7.950000 0.0058013 3.830000 0.3726 0.0611 0.3322 0.0950 0.0029 0.0106 0.0310 0.0233 latest 210 2 Howard University 2 DC 0.7177579 0.2363936 10.550000 0.0049616 4.430000 0.0222 0.8863 0.0092 0.0141 0.0013 0.0052 0.0616 0.0000 latest 36 2 Hampton University 2 VA 0.6915352 0.1975117 9.570000 0.0049616 4.010000 0.0142 0.9593 0.0131 0.0014 0.0025 0.0003 0.0082 0.0008 latest 1275 2 Loyola University Chicago 2 IL 0.6876623 0.2651357 8.770079 0.0045455 3.535827 0.5814 0.0444 0.1425 0.1156 0.0006 0.0028 0.0490 0.0139 2015 cdem %&gt;% arrange(female) %&gt;% filter(female &lt; .50) %&gt;% distinct(university, .keep_all = TRUE) %&gt;% head(10) %&gt;% MakePretty() X control university r_status state female first_gen poverty_rate veteran unemp_rate white black hispanic asian indigenous nhpi nra unknown year 1139 1 New Jersey Institute of Technology 1 NJ 0.1898865 0.3375479 7.624657 0.0034400 3.292901 0.3348 0.0857 0.2210 0.2214 0.0006 0.0006 0.0443 0.0604 2015 1053 1 Missouri University of Science and Technology 2 MO 0.2278168 0.2257366 8.770079 0.0049616 3.535827 0.7815 0.0351 0.0311 0.0299 0.0037 0.0007 0.0566 0.0348 2015 1166 1 Colorado School of Mines 2 CO 0.2631579 0.1719745 8.770079 0.0049616 3.535827 0.7471 0.0104 0.0693 0.0488 0.0013 0.0007 0.0589 0.0088 2015 1138 1 Michigan Technological University 2 MI 0.2765753 0.1732010 8.770079 0.0049616 3.535827 0.8609 0.0108 0.0185 0.0105 0.0037 0.0005 0.0421 0.0254 2015 1149 2 Illinois Institute of Technology 2 IL 0.2832370 0.3137255 8.770079 0.0049616 3.535827 0.3257 0.0585 0.1553 0.1300 0.0034 0.0014 0.2648 0.0428 2015 77 2 Stevens Institute of Technology 2 NJ 0.2847358 0.1549439 5.680000 0.0049616 3.140000 0.6433 0.0219 0.1137 0.1459 0.0009 0.0000 0.0351 0.0392 latest 63 2 Clarkson University 2 NY 0.2998555 0.1528710 7.160000 0.0049616 3.590000 0.8113 0.0245 0.0473 0.0369 0.0030 0.0000 0.0228 0.0188 latest 1113 2 Rensselaer Polytechnic Institute 1 NY 0.3294118 0.1306505 7.624657 0.0037247 3.292901 0.5907 0.0308 0.0813 0.1012 0.0014 0.0002 0.1062 0.0187 2015 1212 2 Rochester Institute of Technology 2 NY 0.3355602 0.2022427 8.770079 0.0049616 3.535827 0.6580 0.0495 0.0711 0.0756 0.0018 0.0002 0.0585 0.0542 2015 1103 2 Worcester Polytechnic Institute 2 MA 0.3477952 0.1429619 8.770079 0.0049616 3.535827 0.6294 0.0232 0.0843 0.0457 0.0024 0.0000 0.1226 0.0625 2015 R1s &lt;- cdem %&gt;% filter(r_status == 1) ggplot(cdem, aes(x = female)) + geom_histogram(bins = 40, color = &quot;black&quot;, fill = &quot;pink&quot;) + labs(title = &quot;Distribution of Female/Male Gender ratio at R1s&quot;) R2s &lt;- cdem %&gt;% filter(r_status == 2) ggplot(R2s, aes(x = female)) + geom_histogram(bins = 40, color = &quot;black&quot;, fill = &quot;skyblue&quot;) + labs(title = &quot;Distribution of Female/Male Gender ratio at R2s&quot;) "],["references.html", "References 6.5 Packages Used", " References #install.packages(&quot;devtools&quot;) #devtools::install_github(&quot;neuropsychology/report&quot;) library(report) #Package for citing 6.5 Packages Used kable(cite_packages(sessionInfo())) %&gt;% kable_styling(full_width = F) References Achim Zeileis, Yves Croissant (2010). Extended Model Formulas in R: Multiple Parts and Multiple Responses. Journal of Statistical Software 34(1), 1-13. doi:10.18637/jss.v034.i01 B. Hofner (2019). papeR: A Toolbox for Writing Pretty Papers and Reports, R package version 1.0-4, https://CRAN.R-project.org/package=papeR. Benjamin Skinner (2020). rscorecard: A Method to Download Department of Education College Scorecard Data. R package version 0.16.0. https://CRAN.R-project.org/package=rscorecard C. Sievert. Interactive Web-Based Data Visualization with R, plotly, and shiny. Chapman and Hall/CRC Florida, 2020. David B. Dahl, David Scott, Charles Roosen, Arni Magnusson and Jonathan Swinton (2019). xtable: Export Tables to LaTeX or HTML. R package version 1.8-4. https://CRAN.R-project.org/package=xtable Erich Neuwirth (2014). RColorBrewer: ColorBrewer Palettes. R package version 1.1-2. https://CRAN.R-project.org/package=RColorBrewer Frank E Harrell Jr, with contributions from Charles Dupont and many others. (2020). Hmisc: Harrell Miscellaneous. R package version 4.4-1. https://CRAN.R-project.org/package=Hmisc H. Wickham. ggplot2: Elegant Graphics for Data Analysis. Springer-Verlag New York, 2016. Hadley Wickham (2011). The Split-Apply-Combine Strategy for Data Analysis. Journal of Statistical Software, 40(1), 1-29. URL http://www.jstatsoft.org/v40/i01/. Hadley Wickham (2019). stringr: Simple, Consistent Wrappers for Common String Operations. R package version 1.4.0. https://CRAN.R-project.org/package=stringr Hadley Wickham (2020). forcats: Tools for Working with Categorical Variables (Factors). R package version 0.5.0. https://CRAN.R-project.org/package=forcats Hadley Wickham (2020). httr: Tools for Working with URLs and HTTP. R package version 1.4.2. https://CRAN.R-project.org/package=httr Hadley Wickham (2020). tidyr: Tidy Messy Data. R package version 1.1.2. https://CRAN.R-project.org/package=tidyr Hadley Wickham, Jim Hester and Romain Francois (2018). readr: Read Rectangular Text Data. R package version 1.3.1. https://CRAN.R-project.org/package=readr Hadley Wickham, Romain François, Lionel Henry and Kirill Müller (2020). dplyr: A Grammar of Data Manipulation. R package version 1.0.2. https://CRAN.R-project.org/package=dplyr Hao Zhu (2020). kableExtra: Construct Complex Table with kable and Pipe Syntax. R package version 1.2.1. https://CRAN.R-project.org/package=kableExtra Jeroen Ooms (2014). The jsonlite Package: A Practical and Consistent Mapping Between JSON Data and R Objects. arXiv:1403.2805 [stat.CO] URL https://arxiv.org/abs/1403.2805. Joe Cheng, Bhaskar Karambelkar and Yihui Xie (2019). leaflet: Create Interactive Web Maps with the JavaScript Leaflet Library. R package version 2.0.3. https://CRAN.R-project.org/package=leaflet John Fox and Sanford Weisberg (2019). An {R} Companion to Applied Regression, Third Edition. Thousand Oaks CA: Sage. URL: https://socialsciences.mcmaster.ca/jfox/Books/Companion/ John Fox, Sanford Weisberg and Brad Price (2020). carData: Companion to Applied Regression Data Sets. R package version 3.0-4. https://CRAN.R-project.org/package=carData Kirill Müller and Hadley Wickham (2020). tibble: Simple Data Frames. R package version 3.0.3. https://CRAN.R-project.org/package=tibble Lionel Henry and Hadley Wickham (2020). purrr: Functional Programming Tools. R package version 0.3.4. https://CRAN.R-project.org/package=purrr Lüdecke D (2020). sjstats: Statistical Functions for Regression Models(Version 0.18.0). doi: 10.5281/zenodo.1284472 (URL:https://doi.org/10.5281/zenodo.1284472), &lt;URL:https://CRAN.R-project.org/package=sjstats&gt;;. Lukasz Komsta and Frederick Novomestky (2015). moments: Moments, cumulants, skewness, kurtosis and related tests. R package version 0.14. https://CRAN.R-project.org/package=moments Makowski, D. &amp; Lüdecke, D. (2019). The report package for R: Ensuring the use of best practices for results reporting. CRAN. Available from https://github.com/easystats/report. doi: . Martijn Tennekes (2017). treemap: Treemap Visualization. R package version 2.4-2. https://CRAN.R-project.org/package=treemap Sarkar, Deepayan (2008) Lattice: Multivariate Data Visualization with R. Springer, New York. ISBN 978-0-387-75968-5 Tennekes M (2018). tmap: Thematic Maps in R. Journal of StatisticalSoftware, 84(6), 1-39. doi: 10.18637/jss.v084.i06 (URL:https://doi.org/10.18637/jss.v084.i06). Therneau T (2020). A Package for Survival Analysis in R. R packageversion 3.1-12, &lt;URL: https://CRAN.R-project.org/package=survival&gt;;. Wickham et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686, https://doi.org/10.21105/joss.01686 "]]
